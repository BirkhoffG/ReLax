{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module\n",
    "\n",
    "> Modules used for defining model architecture and training procedure, which are passed to `train_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from nbdev import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.data import TabularDataModule, load_data\n",
    "from relax.logger import TensorboardLogger\n",
    "from relax.utils import validate_configs, sigmoid, accuracy, init_net_opt, grad_update, make_hk_module, show_doc as show_parser_doc, load_json\n",
    "from relax.trainer import train_model\n",
    "from fastcore.basics import patch\n",
    "from functools import partial\n",
    "from abc import ABC, abstractmethod\n",
    "from copy import deepcopy\n",
    "from relax._ckpt_manager import load_checkpoint, save_checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Networks\n",
    "\n",
    "Networks are [haiku.module](https://dm-haiku.readthedocs.io/en/latest/api.html#common-modules), \n",
    "which define model architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseNetwork(ABC):\n",
    "    \"\"\"BaseNetwork needs a `is_training` argument\"\"\"\n",
    "\n",
    "    def __call__(self, *, is_training: bool):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DenseBlock(hk.Module):\n",
    "    \"\"\"A `DenseBlock` consists of a dense layer, followed by Leaky Relu and a dropout layer.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        output_size: int,  # Output dimensionality.\n",
    "        dropout_rate: float = 0.3,  # Dropout rate.\n",
    "        name: str | None = None,  # Name of the Module\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        self.output_size = output_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray, is_training: bool = True) -> jnp.ndarray:\n",
    "        dropout_rate = self.dropout_rate if is_training else 0.0\n",
    "        # he_uniform\n",
    "        w_init = hk.initializers.VarianceScaling(2.0, \"fan_in\", \"uniform\")\n",
    "        x = hk.Linear(self.output_size, w_init=w_init)(x)\n",
    "        x = jax.nn.leaky_relu(x)\n",
    "        x = hk.dropout(hk.next_rng_key(), dropout_rate, x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(hk.Module):\n",
    "    \"\"\"A `MLP` consists of a list of `DenseBlock` layers.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        sizes: Iterable[int],  # Sequence of layer sizes.\n",
    "        dropout_rate: float = 0.3,  # Dropout rate.\n",
    "        name: str | None = None,  # Name of the Module\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        self.sizes = sizes\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray, is_training: bool = True) -> jnp.ndarray:\n",
    "        for size in self.sizes:\n",
    "            x = DenseBlock(size, self.dropout_rate)(x, is_training)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class PredictiveModelConfigs(BaseParser):\n",
    "    \"\"\"Configurator of `PredictiveModel`.\"\"\"\n",
    "\n",
    "    sizes: List[int]  # Sequence of layer sizes.\n",
    "    dropout_rate: float = 0.3  # Dropout rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PredictiveModel(hk.Module):\n",
    "    \"\"\"A basic predictive model for binary classification.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        sizes: List[int], # Sequence of layer sizes.\n",
    "        dropout_rate: float = 0.3,  # Dropout rate.\n",
    "        name: Optional[str] = None,  # Name of the module.\n",
    "    ):\n",
    "        \"\"\"A basic predictive model for binary classification.\"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.configs = PredictiveModelConfigs(\n",
    "            sizes=sizes, dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray, is_training: bool = True) -> jnp.ndarray:\n",
    "        x = MLP(sizes=self.configs.sizes, dropout_rate=self.configs.dropout_rate)(\n",
    "            x, is_training\n",
    "        )\n",
    "        x = hk.Linear(1)(x)\n",
    "        x = jax.nn.sigmoid(x)\n",
    "        # x = sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `make_hk_module` to create a `haiku.Transformed` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.utils import make_hk_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = make_hk_module(PredictiveModel, sizes=[50, 20, 10], dropout_rate=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make some random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = hk.PRNGSequence(42)\n",
    "xs = random.normal(next(key), (1000, 10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then initalize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = net.init(next(key), xs, is_training=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view model's structure via `jax.tree_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictive_model/linear': {'b': (1,), 'w': (10, 1)},\n",
       " 'predictive_model/mlp/dense_block/linear': {'b': (50,), 'w': (10, 50)},\n",
       " 'predictive_model/mlp/dense_block_1/linear': {'b': (20,), 'w': (50, 20)},\n",
       " 'predictive_model/mlp/dense_block_2/linear': {'b': (10,), 'w': (20, 10)}}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.tree_map(lambda x: x.shape, params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model output is produced via `apply` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = net.apply(params, next(key), xs, is_training=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more usage of `haiku.module`, please refer to \n",
    "[Haiku documentation](https://dm-haiku.readthedocs.io/en/latest/api.html#haiku-fundamentals)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Modules API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "class BaseTrainingModule(ABC):\n",
    "    pass\n",
    "\n",
    "@patch(as_prop=True)\n",
    "def logger(\n",
    "    self:BaseTrainingModule\n",
    ") -> TensorboardLogger | None:\n",
    "    \"\"\"A logger property\"\"\"\n",
    "    pass\n",
    "\n",
    "@patch\n",
    "def log(self:BaseTrainingModule, \n",
    "        name: str, # Name of the log\n",
    "        value: Any # value\n",
    "    ) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseTrainingModule(ABC):\n",
    "    hparams: Dict[str, Any]\n",
    "    logger: TensorboardLogger | None\n",
    "\n",
    "    def save_hyperparameters(self, configs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        self.hparams = deepcopy(configs)\n",
    "        return self.hparams\n",
    "\n",
    "    def init_logger(self, logger: TensorboardLogger):\n",
    "        self.logger = logger\n",
    "\n",
    "    def log(self, name: str, value: Any):\n",
    "        self.log_dict({name: value})\n",
    "\n",
    "    def log_dict(self, dictionary: Dict[str, Any]):\n",
    "        if self.logger:\n",
    "            # self.logger.log({k: np.asarray(v) for k, v in dictionary.items()})\n",
    "            self.logger.log_dict(dictionary)\n",
    "        else:\n",
    "            raise ValueError(\"Logger has not been initliazed.\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def init_net_opt(\n",
    "        self, data_module: TabularDataModule, key: random.PRNGKey\n",
    "    ) -> Tuple[hk.Params, optax.OptState]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def training_step(\n",
    "        self,\n",
    "        params: hk.Params,\n",
    "        opt_state: optax.OptState,\n",
    "        rng_key: random.PRNGKey,\n",
    "        batch: Tuple[jnp.array, jnp.array],\n",
    "    ) -> Tuple[hk.Params, optax.OptState]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def validation_step(\n",
    "        self,\n",
    "        params: hk.Params,\n",
    "        rng_key: random.PRNGKey,\n",
    "        batch: Tuple[jnp.array, jnp.array],\n",
    "    ) -> Dict[str, Any]:\n",
    "        pass\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Training Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PredictiveTrainingModuleConfigs(BaseParser):\n",
    "    \"\"\"Configurator of `PredictiveTrainingModule`.\"\"\"\n",
    "    \n",
    "    lr: float = Field(description='Learning rate.')\n",
    "    sizes: List[int] = Field(description='Sequence of layer sizes.')\n",
    "    dropout_rate: float = Field(0.3, description='Dropout rate') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class PredictiveTrainingModule(BaseTrainingModule):\n",
    "    \"\"\"A training module for predictive models.\"\"\"\n",
    "    \n",
    "    def __init__(self, m_configs: Dict | PredictiveTrainingModuleConfigs):\n",
    "        self.save_hyperparameters(m_configs)\n",
    "        self.configs = validate_configs(m_configs, PredictiveTrainingModuleConfigs)\n",
    "        self.net = make_hk_module(\n",
    "            PredictiveModel, \n",
    "            sizes=self.configs.sizes, \n",
    "            dropout_rate=self.configs.dropout_rate\n",
    "        )\n",
    "        self.opt = optax.adam(learning_rate=self.configs.lr)\n",
    "\n",
    "    @partial(jax.jit, static_argnames=[\"self\", \"is_training\"])\n",
    "    def forward(self, params, rng_key, x, is_training: bool = True):\n",
    "        return self.net.apply(params, rng_key, x, is_training=is_training)\n",
    "    \n",
    "    def pred_fn(self, x, params, rng_key):\n",
    "        return self.forward(params, rng_key, x, is_training=False)\n",
    "\n",
    "    def init_net_opt(self, data_module, key):\n",
    "        X, _ = data_module.train_dataset[:100]\n",
    "        params, opt_state = init_net_opt(\n",
    "            self.net, self.opt, X=X, key=key\n",
    "        )\n",
    "        return params, opt_state\n",
    "\n",
    "    @partial(jax.jit, static_argnames=[\"self\", \"is_training\"])\n",
    "    def loss_fn(self, params, rng_key, batch, is_training: bool = True):\n",
    "        x, y = batch\n",
    "        y_pred = self.net.apply(params, rng_key, x, is_training=is_training)\n",
    "        return jnp.mean(vmap(optax.l2_loss)(y_pred, y))\n",
    "\n",
    "    # def _training_step(self, params, opt_state, rng_key, batch):\n",
    "    #     grads = jax.grad(self.loss_fn)(params, rng_key, batch)\n",
    "    #     upt_params, opt_state = grad_update(grads, params, opt_state, self.opt)\n",
    "    #     return upt_params, opt_state\n",
    "\n",
    "    @partial(jax.jit, static_argnames=[\"self\"])\n",
    "    def _training_step(self, params, opt_state, rng_key, batch):\n",
    "        loss, grads = jax.value_and_grad(self.loss_fn)(params, rng_key, batch)\n",
    "        upt_params, opt_state = grad_update(grads, params, opt_state, self.opt)\n",
    "        return upt_params, opt_state, loss\n",
    "\n",
    "    def training_step(self, params, opt_state, rng_key, batch):\n",
    "        params, opt_state, loss = self._training_step(params, opt_state, rng_key, batch)\n",
    "        self.log_dict({\"train/train_loss_1\": loss.item()})\n",
    "        return params, opt_state\n",
    "\n",
    "    def validation_step(self, params, rng_key, batch):\n",
    "        x, y = batch\n",
    "        y_pred = self.net.apply(params, rng_key, x, is_training=False)\n",
    "        loss = self.loss_fn(params, rng_key, batch, is_training=False)\n",
    "        logs = {\"val/val_loss\": loss.item(), \"val/val_accuracy\": accuracy(y, y_pred)}\n",
    "        self.log_dict(logs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_pred_model(data_name: str) -> Tuple[hk.Params, PredictiveTrainingModule]:\n",
    "\n",
    "    # Fetch the sizes and lr from the configs file\n",
    "    data_dir = Path(os.getcwd()) / \"cf_data\" / data_name \n",
    "    mlp_configs = load_json(data_dir / \"configs.json\" )['mlp_configs']\n",
    "    sizes = mlp_configs[\"sizes\"]\n",
    "    lr = mlp_configs[\"lr\"]\n",
    "\n",
    "    module = PredictiveTrainingModule({'sizes': sizes, 'lr': lr})\n",
    "    param = load_checkpoint(data_dir / \"model\")\n",
    "    return (param, module)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/adult/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 96/96 [00:00<00:00, 394.19batch/s, train/train_loss_1=0.0706]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/credit/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 88/88 [00:00<00:00, 395.03batch/s, train/train_loss_1=0.087] \n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/heloc/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 31/31 [00:00<00:00, 344.25batch/s, train/train_loss_1=0.117]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/oulad/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 96/96 [00:00<00:00, 378.58batch/s, train/train_loss_1=0.0331]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/student_performance/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 16/16 [00:00<00:00, 757.64batch/s, train/train_loss_1=0.129]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/titanic/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 11/11 [00:00<00:00, 620.70batch/s, train/train_loss_1=0.0687]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/german/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 12/12 [00:00<00:00, 647.53batch/s, train/train_loss_1=0.057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/cancer/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 14/14 [00:00<00:00, 734.22batch/s, train/train_loss_1=0.0509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/spam/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 14/14 [00:00<00:00, 412.38batch/s, train/train_loss_1=0.0338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/ozone/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 8/8 [00:00<00:00, 406.84batch/s, train/train_loss_1=0.0232]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/qsar/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 7/7 [00:00<00:00, 324.92batch/s, train/train_loss_1=0.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/bioresponse/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 11/11 [00:00<00:00, 260.42batch/s, train/train_loss_1=0.0556]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/churn/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 21/21 [00:00<00:00, 423.40batch/s, train/train_loss_1=0.0746]\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/chuck/PycharmProjects/temp/ReLax/nbs/cf_data/road/configs.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 655/655 [00:01<00:00, 471.80batch/s, train/train_loss_1=0.0668]\n"
     ]
    }
   ],
   "source": [
    "# slow\n",
    "import shutil\n",
    "\n",
    "DATASET_NAMES = [\"adult\",\"credit\",\"heloc\",\"oulad\",\"student_performance\",\"titanic\",\"german\",\"cancer\",\"spam\", \"ozone\", \"qsar\", \"bioresponse\", \"churn\", \"road\"]\n",
    "\n",
    "for data_name in DATASET_NAMES:\n",
    "    datamodule, data_configs = load_data(data_name = data_name, return_config=True)\n",
    "\n",
    "    # Fetch the sizes and lr from the configs file\n",
    "    data_dir = Path(os.getcwd()) / \"cf_data\" / data_name / \"configs.json\"\n",
    "    print(data_dir)\n",
    "    mlp_configs = load_json(data_dir)['mlp_configs']\n",
    "    sizes = mlp_configs[\"sizes\"]\n",
    "    lr = mlp_configs[\"lr\"]\n",
    "    batch_size = load_json(data_dir)[\"data_configs\"]['batch_size']\n",
    "\n",
    "    params, opt_state = train_model(\n",
    "        PredictiveTrainingModule({'sizes': sizes, 'lr': lr}),\n",
    "        datamodule, t_configs={\n",
    "            'n_epochs': 10, 'batch_size': batch_size, 'monitor_metrics': 'val/val_loss',\n",
    "            'max_n_checkpoints': 1, 'logger_name': data_name\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # get the most recent version and the best epoch stored in the version\n",
    "    version_dir = \"log/{data_name}/\".format(data_name = data_name) # Obtain the all version\n",
    "    latest_version = max([os.path.join(version_dir,v) for v in os.listdir(version_dir) if v.startswith(\"version_\")], key=os.path.getmtime)\n",
    "    epoch = [d for d in os.listdir(latest_version + \"/checkpoints/\".format(data_name = data_name, version = latest_version)) if d.startswith(\"epoch\")][0] # Obtain the epoch value\n",
    "    model_dir = latest_version + \"/checkpoints/{epoch}/model\".format(epoch = epoch)\n",
    "\n",
    "    # update model to the assets\n",
    "    shutil.rmtree(\"assets/{data_name}/model\".format(data_name=data_name), ignore_errors=True)\n",
    "    shutil.copytree(model_dir, \"assets/{data_name}/model\".format(data_name = data_name))\n",
    "\n",
    "    # test: save model under cf_data\n",
    "    shutil.rmtree(\"cf_data/{data_name}/model\".format(data_name=data_name), ignore_errors=True)\n",
    "    shutil.copytree(model_dir, \"cf_data/{data_name}/model\".format(data_name = data_name))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "log = {\"name\":[], \"accuracy\":[],\"rfc accuracy\":[]}\n",
    "for data_name in DATASET_NAMES:\n",
    "    datamodule = load_data(data_name = data_name)\n",
    "    params, module = load_pred_model(data_name)\n",
    "    x,y_true = datamodule.test_dataset[:]\n",
    "    y_pred = module.pred_fn(x = x, params = params, rng_key = random.PRNGKey(0))\n",
    "    assert y_pred.shape == (x.shape[0],1)\n",
    "\n",
    "    # calculate accuracy\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(int)\n",
    "    accuracy = accuracy_score(y_true,y_pred)\n",
    "\n",
    "    log[\"name\"].append(data_name)\n",
    "    log[\"accuracy\"].append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:828: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n",
      "/var/folders/82/4qh59pkn75xdzh4r61851p4h0000gn/T/ipykernel_44608/4004085351.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfc.fit(X_train, y_train)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>rfc accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>0.824100</td>\n",
       "      <td>0.806166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>credit</td>\n",
       "      <td>0.813200</td>\n",
       "      <td>0.813467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>heloc</td>\n",
       "      <td>0.702868</td>\n",
       "      <td>0.719312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oulad</td>\n",
       "      <td>0.926739</td>\n",
       "      <td>0.940361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>student_performance</td>\n",
       "      <td>0.901840</td>\n",
       "      <td>0.920245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>titanic</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.802691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>german</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cancer</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.916084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>0.933970</td>\n",
       "      <td>0.943527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ozone</td>\n",
       "      <td>0.933754</td>\n",
       "      <td>0.949527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>qsar</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bioresponse</td>\n",
       "      <td>0.787846</td>\n",
       "      <td>0.801706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>churn</td>\n",
       "      <td>0.806360</td>\n",
       "      <td>0.781942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>road</td>\n",
       "      <td>0.751262</td>\n",
       "      <td>0.790738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name  accuracy  rfc accuracy\n",
       "0                 adult  0.824100      0.806166\n",
       "1                credit  0.813200      0.813467\n",
       "2                 heloc  0.702868      0.719312\n",
       "3                 oulad  0.926739      0.940361\n",
       "4   student_performance  0.901840      0.920245\n",
       "5               titanic  0.816143      0.802691\n",
       "6                german  0.756000      0.756000\n",
       "7                cancer  0.909091      0.916084\n",
       "8                  spam  0.933970      0.943527\n",
       "9                 ozone  0.933754      0.949527\n",
       "10                 qsar  0.848485      0.863636\n",
       "11          bioresponse  0.787846      0.801706\n",
       "12                churn  0.806360      0.781942\n",
       "13                 road  0.751262      0.790738"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "log[\"rfc accuracy\"] = []\n",
    "for data_name in DATASET_NAMES:\n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    datamodule = load_data(data_name = data_name)\n",
    "    X_train, y_train = datamodule.train_dataset[:]\n",
    "    rfc.fit(X_train, y_train)\n",
    "    X_test, y_test = datamodule.test_dataset[:]\n",
    "    y_pred = rfc.predict(X_test)\n",
    "\n",
    "    # calculate accuracy\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(int)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    log[\"rfc accuracy\"].append(accuracy)\n",
    "\n",
    "pd.DataFrame.from_dict(log)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
