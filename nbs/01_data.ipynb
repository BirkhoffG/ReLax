{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Module\n",
    "\n",
    "> `DataModule` for training parametric models, generating and benchmarking CF explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 10:15:57.546893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using JAX backend.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.utils import load_json, validate_configs, cat_normalize, get_config\n",
    "from relax.base import *\n",
    "from relax.data_utils import *\n",
    "import jax\n",
    "from jax import numpy as jnp, random as jrand, lax, Array\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "# from sklearn.base import TransformerMixin\n",
    "# from sklearn.utils.validation import check_is_fitted, NotFittedError\n",
    "from urllib.request import urlretrieve\n",
    "# from relax.data.loader import Dataset, ArrayDataset, DataLoader, DataloaderBackends\n",
    "from pydantic.fields import ModelField, Field\n",
    "from typing import List, Dict, Union, Optional, Tuple, Callable, Any, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module Interfaces\n",
    "\n",
    "High-level interfaces for `DataModule`. Docs to be added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseDataModule(BaseModule):\n",
    "    \"\"\"DataModule Interface\"\"\"\n",
    "\n",
    "    def prepare(self, *args, **kwargs):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def apply_constraints(self, x: Array, cf: Array, hard: bool = False, **kwargs) -> Array:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def apply_regularization(self, x: Array, cf: Array, hard: bool = False, **kwargs) -> float:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabula Data Module\n",
    "\n",
    "`DataModule` for processing tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataModuleConfig(BaseConfig):\n",
    "    \"\"\"Configurator of `TabularDataModule`.\"\"\"\n",
    "\n",
    "    data_dir: str = Field(description=\"The directory of dataset.\")\n",
    "    data_name: str = Field(description=\"The name of `DataModule`.\")\n",
    "    continous_cols: List[str] = Field([], description=\"Continuous features/columns in the data.\")\n",
    "    discret_cols: List[str] = Field([], description=\"Categorical features/columns in the data.\")\n",
    "    imutable_cols: List[str] = Field([], description=\"Immutable features/columns in the data.\")\n",
    "    continuous_transformation: str = Field('minmax', description=\"Transformation for continuous features.\")\n",
    "    discret_transformation: str = Field('ohe', description=\"Transformation for categorical features.\")\n",
    "    sample_frac: Optional[float] = Field(\n",
    "        None, description=\"Sample fraction of the data. Default to use the entire data.\", ge=0., le=1.0\n",
    "    )\n",
    "    train_indices: List[int] = Field([], description=\"Indices of training data.\")\n",
    "    test_indices: List[int] = Field([], description=\"Indices of testing data.\")\n",
    "    \n",
    "    # normalizer: Optional[str] = Field(\n",
    "    #     default_factory=lambda: MinMaxScaler(),\n",
    "    #     description=\"Sklearn scalar for continuous features. Can be unfitted, fitted, or None. \"\n",
    "    #     \"If not fitted, the `TabularDataModule` will fit using the training data. If fitted, no fitting will be applied. \"\n",
    "    #     \"If `None`, no transformation will be applied. Default to `MinMaxScaler()`.\"\n",
    "    # )\n",
    "    # encoder: Optional[str] = Field(\n",
    "    #     default_factory=lambda: OneHotEncoder(sparse=False),\n",
    "    #     description=\"Fitted encoder for categorical features. Can be unfitted, fitted, or None. \"\n",
    "    #     \"If not fitted, the `TabularDataModule` will fit using the training data. If fitted, no fitting will be applied. \"\n",
    "    #     \"If `None`, no transformation will be applied. Default to `OneHotEncoder(sparse=False)`.\"\n",
    "    # )\n",
    "\n",
    "    def shuffle(self, data: Array, test_size: float, seed: int = None):\n",
    "        \"\"\"Shuffle data with a seed.\"\"\"\n",
    "        if seed is None:\n",
    "            seed = get_config().global_seed\n",
    "        key = jrand.PRNGKey(seed)\n",
    "        total_length = data.shape[0]\n",
    "        train_length = int((1 - test_size) * total_length)\n",
    "        self.train_indices = jrand.permutation(key, total_length)[:train_length].tolist()\n",
    "        self.test_indices = jrand.permutation(key, total_length)[train_length:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "config = DataModuleConfig(data_name=\"TabularDataModule\", data_dir=\"data\", continous_cols=[], discret_cols=[], imutable_cols=[])\n",
    "config.shuffle(data=np.arange(100), test_size=0.2)\n",
    "assert len(config.train_indices) == 100 * 0.8\n",
    "assert len(config.test_indices) == 100 * 0.2\n",
    "assert isinstance(config.train_indices, list)\n",
    "assert isinstance(config.test_indices, list)\n",
    "\n",
    "configs_dict = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    \"continous_cols\": [\"age\", \"hours_per_week\"],\n",
    "    \"discret_cols\": [\"workclass\", \"education\", \"marital_status\",\"occupation\"],\n",
    "    \"imutable_cols\": [\"age\", \"workclass\", \"marital_status\"],\n",
    "    \"sample_frac\": 0.1,\n",
    "}\n",
    "configs = DataModuleConfig(**configs_dict)\n",
    "assert len(configs.train_indices) == 0\n",
    "assert len(configs.test_indices) == 0\n",
    "assert config.continuous_transformation == 'minmax'\n",
    "assert config.discret_transformation == 'ohe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DataModule(BaseDataModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        config, \n",
    "        data: pd.DataFrame = None,\n",
    "        features: List[Feature] = None,\n",
    "        label: Feature = None,\n",
    "    ):\n",
    "        config = validate_configs(config, DataModuleConfig)\n",
    "        if data is None:\n",
    "            data = pd.read_csv(config.data_dir)\n",
    "        self._data = data\n",
    "        features = self.convert_to_features(config, data, features)\n",
    "        label = self.convert_to_label(config, data, label)\n",
    "        self.prepare(features, label)\n",
    "        config.shuffle(self.xs, test_size=0.25)\n",
    "        super().__init__(config, name=config.data_name)\n",
    "\n",
    "    def convert_to_features(\n",
    "        self, \n",
    "        config: DataModuleConfig, \n",
    "        data: pd.DataFrame, \n",
    "        features: list[Feature] = None\n",
    "    ):\n",
    "        to_feature = lambda col, data, is_continuous: Feature(\n",
    "                name=col, data=data[col].to_numpy().reshape(-1, 1),\n",
    "                transformation=config.continuous_transformation if is_continuous else config.discret_transformation,\n",
    "                is_immutable=col in config.imutable_cols\n",
    "            )\n",
    "\n",
    "        if features is not None:\n",
    "            return features\n",
    "        \n",
    "        cont_features = [to_feature(col, data, True) for col in config.continous_cols]\n",
    "        cat_features = [to_feature(col, data, False) for col in config.discret_cols]\n",
    "        return cont_features + cat_features        \n",
    "        \n",
    "    def convert_to_label(self, config: DataModuleConfig, data: pd.DataFrame, label: Feature = None):\n",
    "        if label is not None:\n",
    "            return label\n",
    "        \n",
    "        label_col = data.columns[-1]\n",
    "        return Feature(\n",
    "            name=label_col, data=data[label_col].to_numpy().reshape(-1, 1),\n",
    "            transformation='identity',\n",
    "            is_immutable=label_col in config.imutable_cols\n",
    "        )\n",
    "        \n",
    "    def prepare(self, features, label):\n",
    "        if features is not None and label is not None:\n",
    "            self._features = FeaturesList(features)\n",
    "            self._label = label\n",
    "        elif features is None:\n",
    "            raise ValueError(\"Features cannot be None.\")\n",
    "        elif label is None:\n",
    "            raise ValueError(\"Label cannot be None.\")\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def xs(self) -> Array:\n",
    "        return self._features.transformed_data\n",
    "    \n",
    "    @property\n",
    "    def ys(self) -> Array:\n",
    "        return self._label.transformed_data\n",
    "\n",
    "    @property\n",
    "    def dataset(self) -> Tuple[Array, Array]:\n",
    "        return (self.xs, self.ys)\n",
    "    \n",
    "    def _get_data(self, indices):\n",
    "        if isinstance(indices, list):\n",
    "            indices = jnp.array(indices)\n",
    "        return (self.xs[indices], self.ys[indices])\n",
    "        \n",
    "    def __getitem__(self, name: str):\n",
    "        if name == 'train':\n",
    "            return self._get_data(self.config.train_indices)\n",
    "        elif name in ['valid', 'test']:\n",
    "            return self._get_data(self.config.test_indices)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown data name: {name}. Should be one of ['train', 'valid', 'test']\")\n",
    "        \n",
    "    def apply_constraints(self, x: Array, cf: Array, hard: bool = False) -> Array:\n",
    "        return self._features.apply_constraints(x, cf, hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DataModule(configs)\n",
    "xs = dm['train'][0]\n",
    "cfs = jrand.uniform(jrand.PRNGKey(0), shape=xs.shape, minval=0.01, maxval=0.99)\n",
    "cfs = dm.apply_constraints(xs, cfs, hard=False)\n",
    "assert cfs.shape == xs.shape\n",
    "\n",
    "cfs = dm.apply_constraints(xs, cfs, hard=True)\n",
    "assert cfs.shape == xs.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "DEFAULT_DATA_CONFIGS = {\n",
    "    'adult': {\n",
    "        'data' :'assets/adult/data.csv',\n",
    "        'conf' :'assets/adult/configs.json',\n",
    "        'model' :'assets/adult/model'\n",
    "    },\n",
    "    'heloc': {\n",
    "        'data': 'assets/heloc/data.csv',\n",
    "        'conf': 'assets/heloc/configs.json',\n",
    "        'model' :'assets/heloc/model'\n",
    "    },\n",
    "    'oulad': {\n",
    "        'data': 'assets/oulad/data.csv',\n",
    "        'conf': 'assets/oulad/configs.json',\n",
    "        'model' :'assets/oulad/model'\n",
    "    },\n",
    "    'credit': {\n",
    "        'data': 'assets/credit/data.csv',\n",
    "        'conf': 'assets/credit/configs.json',\n",
    "        'model' :'assets/credit/model'\n",
    "    },\n",
    "    'cancer': {\n",
    "        'data': 'assets/cancer/data.csv',\n",
    "        'conf': 'assets/cancer/configs.json',\n",
    "        'model' :'assets/cancer/model'\n",
    "    },\n",
    "    'student_performance': {\n",
    "        'data': 'assets/student_performance/data.csv',\n",
    "        'conf': 'assets/student_performance/configs.json',\n",
    "        'model' :'assets/student_performance/model'\n",
    "    },\n",
    "    'titanic': {\n",
    "        'data': 'assets/titanic/data.csv',\n",
    "        'conf': 'assets/titanic/configs.json',\n",
    "        'model' :'assets/titanic/model'\n",
    "    },\n",
    "    'german': {\n",
    "        'data': 'assets/german/data.csv',\n",
    "        'conf': 'assets/german/configs.json',\n",
    "        'model' :'assets/german/model'\n",
    "    },\n",
    "    'spam': {\n",
    "        'data': 'assets/spam/data.csv',\n",
    "        'conf': 'assets/spam/configs.json',\n",
    "        'model' :'assets/spam/model'\n",
    "    },\n",
    "    'ozone': {\n",
    "        'data': 'assets/ozone/data.csv',\n",
    "        'conf': 'assets/ozone/configs.json',\n",
    "        'model' :'assets/ozone/model'\n",
    "    },\n",
    "    'qsar': {\n",
    "        'data': 'assets/qsar/data.csv',\n",
    "        'conf': 'assets/qsar/configs.json',\n",
    "        'model' :'assets/qsar/model'\n",
    "    },\n",
    "    'bioresponse': {\n",
    "        'data': 'assets/bioresponse/data.csv',\n",
    "        'conf': 'assets/bioresponse/configs.json',\n",
    "        'model' :'assets/bioresponse/model'\n",
    "    },\n",
    "    'churn': {\n",
    "        'data': 'assets/churn/data.csv',\n",
    "        'conf': 'assets/churn/configs.json',\n",
    "        'model' :'assets/churn/model'\n",
    "    },\n",
    "    'road': {\n",
    "        'data': 'assets/road/data.csv',\n",
    "        'conf': 'assets/road/configs.json',\n",
    "        'model' :'assets/road/model'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, '30 Days Delinquent', nan, ..., 'Derogatory Comment',\n",
       "       'Never Delinquent', nan], dtype=object)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(DEFAULT_DATA_CONFIGS['heloc']['data'])['MaxDelq2PublicRecLast12M'].to_numpy(na_value=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading adult...\n",
      "Loading heloc...\n",
      "Loading oulad...\n",
      "Loading credit...\n",
      "Loading cancer...\n",
      "Loading student_performance...\n",
      "Loading titanic...\n",
      "Loading german...\n",
      "Loading spam...\n",
      "Loading ozone...\n",
      "Loading qsar...\n",
      "Loading bioresponse...\n",
      "Loading churn...\n",
      "Loading road...\n"
     ]
    }
   ],
   "source": [
    "for data_name in DEFAULT_DATA_CONFIGS.keys():\n",
    "    print(f\"Loading {data_name}...\")\n",
    "    conf_path = DEFAULT_DATA_CONFIGS[data_name]['conf']\n",
    "    config = load_json(conf_path)['data_configs']\n",
    "    dm_config = DataModuleConfig(**config)\n",
    "    dm = DataModule(dm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_json('assets/adult/configs.json')['data_configs']\n",
    "dm_config = DataModuleConfig(**config)\n",
    "dm = DataModule(dm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _validate_dataname(data_name: str):\n",
    "    if data_name not in DEFAULT_DATA_CONFIGS.keys():\n",
    "        raise ValueError(f'`data_name` must be one of {DEFAULT_DATA_CONFIGS.keys()}, '\n",
    "            f'but got data_name={data_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(\n",
    "    data_name: str, # The name of data\n",
    "    return_config: bool = False, # Return `data_config `or not\n",
    "    data_configs: dict = None # Data configs to override default configuration\n",
    ") -> TabularDataModule | Tuple[TabularDataModule, TabularDataModuleConfigs]: \n",
    "    \"\"\"High-level util function for loading `data` and `data_config`.\"\"\"\n",
    "    \n",
    "    _validate_dataname(data_name)\n",
    "\n",
    "    # get data/config urls\n",
    "    _data_path = DEFAULT_DATA_CONFIGS[data_name]['data']\n",
    "    _conf_path = DEFAULT_DATA_CONFIGS[data_name]['conf']\n",
    "    \n",
    "    data_url = f\"https://github.com/BirkhoffG/ReLax/raw/master/{_data_path}\"\n",
    "    conf_url = f\"https://github.com/BirkhoffG/ReLax/raw/master/{_conf_path}\"\n",
    "\n",
    "    # create new dir\n",
    "    data_dir = Path(os.getcwd()) / \"cf_data\" / data_name\n",
    "    if not data_dir.exists():\n",
    "        os.makedirs(data_dir)\n",
    "    data_path = data_dir / 'data.csv'\n",
    "    conf_path = data_dir / 'configs.json'\n",
    "\n",
    "    # download data/configs\n",
    "    if not data_path.is_file():\n",
    "        urlretrieve(data_url, data_path)    \n",
    "    if not conf_path.is_file():\n",
    "        urlretrieve(conf_url, conf_path)\n",
    "\n",
    "    # read config\n",
    "    config = load_json(conf_path)['data_configs']\n",
    "    config['data_dir'] = str(data_path)\n",
    "\n",
    "    if not (data_configs is None):\n",
    "        config.update(data_configs)\n",
    "\n",
    "    config = TabularDataModuleConfigs(**config)\n",
    "    data_module = TabularDataModule(config)\n",
    "\n",
    "    if return_config:\n",
    "        return data_module, config\n",
    "    else:\n",
    "        return data_module\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_data` easily loads example datasets by passing the `data_name`. \n",
    "For example, you can load the [adult](https://archive.ics.uci.edu/ml/datasets/adult) as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data(data_name = 'adult')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underlying, `load_data` loads the default `data_configs`. To access this `data_configs`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, data_configs = load_data(data_name = 'adult', return_config=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to override some of the data configs, \n",
    "you can pass it as an auxillary argumenet in `data_configs`. \n",
    "For example, if you want to use only 10% of the data, you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data(\n",
    "    data_name = 'adult', data_configs={'sample_frac': 0.1}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supported Datasets\n",
    "\n",
    "`load_data` currently supports following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Cont Features</th>\n",
       "      <th># Cat Features</th>\n",
       "      <th># of Data Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heloc</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>10459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oulad</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>32593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_performance</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titanic</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ozone</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>2534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsar</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioresponse</th>\n",
       "      <td>1776</td>\n",
       "      <td>0</td>\n",
       "      <td>3751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>111762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     # Cont Features  # Cat Features  # of Data Points\n",
       "adult                              2               6             32561\n",
       "heloc                             21               2             10459\n",
       "oulad                             23               8             32593\n",
       "credit                            20               3             30000\n",
       "cancer                            30               0               569\n",
       "student_performance                2              14               649\n",
       "titanic                            2              24               891\n",
       "german                             7              13              1000\n",
       "spam                              57               0              4601\n",
       "ozone                             72               0              2534\n",
       "qsar                              38               3              1055\n",
       "bioresponse                     1776               0              3751\n",
       "churn                              3              16              7043\n",
       "road                              29               3            111762"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "def display_data_attrbutes(names: list):\n",
    "    attrs = {\n",
    "        '# Cont Features': { data_name: 0 for data_name in names}, \n",
    "        '# Cat Features': { data_name: 0 for data_name in names},\n",
    "        '# of Data Points': { data_name: 0 for data_name in names}, \n",
    "    }\n",
    "    for data_name in names:\n",
    "        dm, config = load_data(data_name, return_config=True)\n",
    "        attrs['# Cont Features'][data_name] = len(config.continous_cols)\n",
    "        attrs['# Cat Features'][data_name] = len(config.discret_cols)\n",
    "        attrs['# of Data Points'][data_name] = len(dm.data)\n",
    "\n",
    "        # run tests\n",
    "        check_datamodule(dm, config)\n",
    "    return pd.DataFrame.from_dict(attrs)\n",
    "\n",
    "display_data_attrbutes(DEFAULT_DATA_CONFIGS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adult', 'heloc', 'oulad', 'credit', 'cancer', 'student_performance', 'titanic', 'german', 'spam', 'ozone', 'qsar', 'bioresponse', 'churn', 'road'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_DATA_CONFIGS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for data_name in DEFAULT_DATA_CONFIGS.keys():\n",
    "    dm, config = load_data(\n",
    "        data_name, return_config=True, data_configs=dict(sample_frac=0.1)\n",
    "    )\n",
    "    assert config.sample_frac == 0.1\n",
    "    check_datamodule(dm, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
