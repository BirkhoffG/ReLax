{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from cfnet.import_essentials import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def validate_configs(\n",
    "    configs: Union[Dict[str, Any], BaseParser], # configs\n",
    "    config_cls: BaseParser # config class\n",
    "):\n",
    "    if not isinstance(configs, config_cls):\n",
    "        configs = config_cls(**configs)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfnet.training_module import PredictiveTrainingModuleConfigs, CounterNetTrainingModuleConfigs\n",
    "\n",
    "configs = {\n",
    "    'lr': 0.1,\n",
    "    'lambda_1': 1.,\n",
    "    'lambda_2': 1.,\n",
    "    'lambda_3': 1.,\n",
    "}\n",
    "p_config = validate_configs(configs, PredictiveTrainingModuleConfigs)\n",
    "cf_config = validate_configs(configs, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "assert isinstance(p_config, PredictiveTrainingModuleConfigs)\n",
    "assert isinstance(cf_config, CounterNetTrainingModuleConfigs)\n",
    "\n",
    "assert not isinstance(p_config, dict)\n",
    "assert not isinstance(cf_config, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def load_json(f_name: str) -> Dict[str, Any]:\n",
    "    with open(f_name) as f: return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "# https://github.com/d2l-ai/d2l-en/blob/d9a3f6ac0e86468159d7b69345a1732bbe3ce1c7/d2l/torch.py#L100\n",
    "def add_to_class(Class):\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def cat_normalize(cf, cat_arrays, cat_idx: int, hard: bool=False):\n",
    "    cf_cont = cf[:, :cat_idx]\n",
    "    normalized_cf = [cf_cont]\n",
    "\n",
    "    for col in cat_arrays:\n",
    "        cat_end_idx = cat_idx + len(col)\n",
    "        _cf_cat = cf[:, cat_idx:cat_end_idx]\n",
    "\n",
    "        cf_cat = lax.cond(\n",
    "            hard,\n",
    "            true_fun=lambda x: jax.nn.one_hot(\n",
    "                jnp.argmax(x, axis=-1), len(col)\n",
    "            ),\n",
    "            false_fun=lambda x: jax.nn.softmax(x, axis=-1),\n",
    "            operand=_cf_cat\n",
    "        )\n",
    "\n",
    "        cat_idx = cat_end_idx\n",
    "        normalized_cf.append(cf_cat)\n",
    "    return jnp.concatenate(normalized_cf, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def binary_cross_entropy(y_pred: chex.Array, y: chex.Array) -> chex.Array:\n",
    "    return -(y * jnp.log(y_pred) + (1 - y) * jnp.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def accuracy(y_true: jnp.ndarray, y_pred: jnp.ndarray) -> jnp.DeviceArray:\n",
    "    y_true, y_pred = map(jnp.round, (y_true, y_pred))\n",
    "    return jnp.mean(jnp.equal(y_true, y_pred))\n",
    "\n",
    "def dist(x: jnp.ndarray, cf: jnp.ndarray, ord: int = 2) -> jnp.DeviceArray:\n",
    "    dist = jnp.linalg.norm(x - cf, ord=ord, axis=-1, keepdims=True)\n",
    "    return jnp.mean(vmap(jnp.sum)(dist))\n",
    "\n",
    "def proximity(x: jnp.ndarray, cf: jnp.ndarray) -> jnp.DeviceArray:\n",
    "    return dist(x, cf, ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = jnp.array([\n",
    "    [1., 2., 3., 1.],\n",
    "    [1., -1., 4., 1.],\n",
    "])\n",
    "n = jnp.array([\n",
    "    [0., -1., 3., 1.],\n",
    "    [1., 2., 4., 1.],\n",
    "])\n",
    "assert proximity(m, n).item() == 3.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
