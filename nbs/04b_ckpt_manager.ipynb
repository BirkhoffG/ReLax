{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Manage the model and optimizer checkpoints.\n",
    "output-file: ckpt_manager.html\n",
    "title: Checkpoint Manager\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp _ckpt_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/miniconda3/envs/nbdev2/lib/python3.7/site-packages/haiku/_src/data_structures.py:37: FutureWarning: jax.tree_structure is deprecated, and will be removed in a future release. Use jax.tree_util.tree_structure instead.\n",
      "  PyTreeDef = type(jax.tree_structure(None))\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "from cfnet.import_essentials import *\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# https://github.com/deepmind/dm-haiku/issues/18#issuecomment-981814403\n",
    "def save_checkpoint(state, ckpt_dir: Path):\n",
    "    with open(os.path.join(ckpt_dir, \"params.npy\"), \"wb\") as f:\n",
    "        for x in jax.tree_leaves(state):\n",
    "            np.save(f, x, allow_pickle=False)\n",
    "\n",
    "    tree_struct = jax.tree_map(lambda t: 0, state)\n",
    "    with open(os.path.join(ckpt_dir, \"tree.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(tree_struct, f)\n",
    "\n",
    "def load_checkpoint(ckpt_dir: Path):\n",
    "    with open(os.path.join(ckpt_dir, \"tree.pkl\"), \"rb\") as f:\n",
    "        tree_struct = pickle.load(f)\n",
    "\n",
    "    leaves, treedef = jax.tree_flatten(tree_struct)\n",
    "    with open(os.path.join(ckpt_dir, \"params.npy\"), \"rb\") as f:\n",
    "        flat_state = [np.load(f) for _ in leaves]\n",
    "\n",
    "    return jax.tree_unflatten(treedef, flat_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CheckpointManager:\n",
    "    def __init__(self,\n",
    "                 log_dir: Union[Path, str],\n",
    "                 monitor_metrics: Optional[str],\n",
    "                 max_n_checkpoints: int = 3):\n",
    "        self.log_dir = Path(log_dir)\n",
    "        self.monitor_metrics = monitor_metrics\n",
    "        self.max_n_checkpoints = max_n_checkpoints\n",
    "        self.checkpoints = OrderedDict()\n",
    "        self.n_checkpoints = 0\n",
    "        if self.monitor_metrics is None:\n",
    "            warnings.warn(\"`monitor_metrics` is not specified in `CheckpointManager`. No checkpoints will be stored.\")\n",
    "\n",
    "    # update checkpoints based on monitor_metrics\n",
    "    def update_checkpoints(self,\n",
    "                           params: hk.Params,\n",
    "                           opt_state: optax.OptState,\n",
    "                           epoch_logs: Dict[str, float],\n",
    "                           epochs: int,\n",
    "                           steps: Optional[int] = None):\n",
    "        if self.monitor_metrics is None:\n",
    "            return\n",
    "        metric = float(epoch_logs[self.monitor_metrics])\n",
    "        if steps:\n",
    "            ckpt_name = f'epoch={epochs}_step={steps}'\n",
    "        else:\n",
    "            ckpt_name = f'epoch={epochs}'\n",
    "\n",
    "        if self.n_checkpoints < self.max_n_checkpoints:\n",
    "            self.checkpoints[metric] = ckpt_name\n",
    "            self.save_net_opt(params, opt_state, ckpt_name)\n",
    "            self.n_checkpoints += 1\n",
    "        else:\n",
    "            old_metric, old_ckpt_name = self.checkpoints.popitem(last=True)\n",
    "            if metric < old_metric:\n",
    "                self.checkpoints[metric] = ckpt_name\n",
    "                self.save_net_opt(params, opt_state, ckpt_name)\n",
    "                self.delete_net_opt(old_ckpt_name)\n",
    "            else:\n",
    "                self.checkpoints[old_metric] = old_ckpt_name\n",
    "\n",
    "        self.checkpoints = OrderedDict(\n",
    "            sorted(self.checkpoints.items(), key=lambda x: x[0]))\n",
    "\n",
    "    def save_net_opt(self, params, opt_state, ckpt_name: str):\n",
    "        ckpt_dir = self.log_dir / f'{ckpt_name}'\n",
    "        ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "        model_ckpt_dir = ckpt_dir / 'model'\n",
    "        opt_ckpt_dir = ckpt_dir / 'opt'\n",
    "        # create dirs for storing states of model and optimizer\n",
    "        model_ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "        opt_ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
    "        # save model and optimizer states\n",
    "        save_checkpoint(params, model_ckpt_dir)\n",
    "        save_checkpoint(opt_state, opt_ckpt_dir)\n",
    "\n",
    "    def delete_net_opt(self, ckpt_name: str):\n",
    "        ckpt_dir = self.log_dir / f'{ckpt_name}'\n",
    "        shutil.rmtree(ckpt_dir)\n",
    "\n",
    "    # deprecated\n",
    "    def load_net_opt(self, ckpt_name: str):\n",
    "        ckpt_dir = self.log_dir / f'{ckpt_name}'\n",
    "        model_ckpt_dir = ckpt_dir / 'model'\n",
    "        opt_ckpt_dir = ckpt_dir / 'opt'\n",
    "        # load model and optimizer states\n",
    "        params = load_checkpoint(model_ckpt_dir)\n",
    "        opt_state = load_checkpoint(opt_ckpt_dir)\n",
    "        return params, opt_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'make_model' from 'cfnet.utils' (/home/birk/code/cfnet/cfnet/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2986/3377493498.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcfnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcfnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPredictiveTrainingModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m data_configs = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"data_dir\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assets/data/s_adult.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/cfnet/cfnet/training_module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorboardLogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvalidate_configs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_normalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproximity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_net_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mABC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'make_model' from 'cfnet.utils' (/home/birk/code/cfnet/cfnet/utils.py)"
     ]
    }
   ],
   "source": [
    "from cfnet.datasets import TabularDataModule\n",
    "from cfnet.training_module import PredictiveTrainingModule\n",
    "\n",
    "data_configs = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    \"batch_size\": 256,\n",
    "    'sample_frac': 0.1,\n",
    "    \"continous_cols\": [\n",
    "        \"age\",\n",
    "        \"hours_per_week\"\n",
    "    ],\n",
    "    \"discret_cols\": [\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"marital_status\",\n",
    "        \"occupation\",\n",
    "        \"race\",\n",
    "        \"gender\"\n",
    "    ],\n",
    "}\n",
    "# dm = \n",
    "m_configs = {\n",
    "    \"sizes\": [50, 10, 50],\n",
    "    \"dropout_rate\": 0.3,\n",
    "    'lr': 0.003,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "key = hk.PRNGSequence(42)\n",
    "ckpt_manager = CheckpointManager(\n",
    "    log_dir='log', \n",
    "    monitor_metrics='train/train_loss_1',\n",
    "    max_n_checkpoints=3\n",
    ")\n",
    "dm = TabularDataModule(data_configs)\n",
    "module = PredictiveTrainingModule(m_configs)\n",
    "params, opt_state = module.init_net_opt(dm, next(key))\n",
    "logs = {'train/train_loss_1': 0.1}\n",
    "ckpt_manager.update_checkpoints(params, opt_state, logs, epochs=1)\n",
    "logs = {'train/train_loss_1': 0.2}\n",
    "ckpt_manager.update_checkpoints(params, opt_state, logs, epochs=2)\n",
    "logs = {'train/train_loss_1': 0.15}\n",
    "ckpt_manager.update_checkpoints(params, opt_state, logs, epochs=3)\n",
    "logs = {'train/train_loss_1': 0.05}\n",
    "ckpt_manager.update_checkpoints(params, opt_state, logs, epochs=4)\n",
    "logs = {'train/train_loss_1': 0.14}\n",
    "ckpt_manager.update_checkpoints(params, opt_state, logs, epochs=5)\n",
    "assert ckpt_manager.n_checkpoints == len(ckpt_manager.checkpoints)\n",
    "assert ckpt_manager.checkpoints.popitem(last=True)[0] == 0.14\n",
    "\n",
    "shutil.rmtree(Path('log/epoch=1'), ignore_errors=True)\n",
    "shutil.rmtree(Path('log/epoch=2'), ignore_errors=True)\n",
    "shutil.rmtree(Path('log/epoch=3'), ignore_errors=True)\n",
    "shutil.rmtree(Path('log/epoch=4'), ignore_errors=True)\n",
    "shutil.rmtree(Path('log/epoch=5'), ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('nbdev2')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
