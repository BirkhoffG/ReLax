{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "> Evaluating and benchmarking the quality of CF explanations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# default_exp evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from cfnet.import_essentials import *\n",
    "from cfnet.train import train_model, TensorboardLogger\n",
    "from cfnet.datasets import TabularDataModule\n",
    "from cfnet.interfaces import BaseCFExplanationModule, LocalCFExplanationModule\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@dataclass\n",
    "class CFExplanationResults:\n",
    "    cf_name: str        # cf method's name\n",
    "    dataset_name: str   # dataset name\n",
    "    X: jnp.DeviceArray  # input\n",
    "    y: jnp.DeviceArray  # label\n",
    "    cfs: jnp.DeviceArray # generated cf explanation of `X`\n",
    "    total_time: float   # total runtime\n",
    "    pred_fn: Callable[[jnp.DeviceArray], jnp.DeviceArray] # predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating CF Explanation Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_cf_results(\n",
    "    cf_module: BaseCFExplanationModule,\n",
    "    dm: TabularDataModule,\n",
    "    pred_fn: Optional[Callable[[jnp.DeviceArray], jnp.DeviceArray]] = None,\n",
    "    params: Optional[hk.Params] = None, # params of `cf_module`\n",
    "    rng_key: Optional[random.PRNGKey] = None \n",
    ") -> CFExplanationResults:\n",
    "    # validate arguments\n",
    "    if (pred_fn is None) and (params is None) and (rng_key is None):\n",
    "        raise ValueError(\"A valid `pred_fn: Callable[jnp.DeviceArray], jnp.DeviceArray]` or `params: hk.Params` needs to be passed.\")\n",
    "\n",
    "    X, y = dm.test_dataset[:]\n",
    "    current_time = time.time()\n",
    "    if pred_fn:\n",
    "        cfs = cf_module.generate_cfs(X, pred_fn)\n",
    "    else:\n",
    "        cfs = cf_module.generate_cfs(X, params, rng_key)\n",
    "        pred_fn = lambda x: cf_module.predict(deepcopy(params), rng_key, x)\n",
    "    total_time = time.time() - current_time\n",
    "\n",
    "    return CFExplanationResults(\n",
    "        X=X, y=y, cfs=cfs, total_time=total_time,\n",
    "        pred_fn=pred_fn,\n",
    "        cf_name=cf_module.name, dataset_name=dm.data_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def generate_cf_results_local_exp(\n",
    "    cf_module: LocalCFExplanationModule, \n",
    "    dm: TabularDataModule, \n",
    "    pred_fn: Callable[[jnp.DeviceArray], jnp.DeviceArray]\n",
    ") -> CFExplanationResults:\n",
    "    return generate_cf_results(cf_module, dm, pred_fn=pred_fn)\n",
    "\n",
    "def generate_cf_results_cfnet(\n",
    "    cf_module: LocalCFExplanationModule, \n",
    "    dm: TabularDataModule, \n",
    "    params: Optional[hk.Params] = None, # params of `cf_module`\n",
    "    rng_key: Optional[random.PRNGKey] = None \n",
    ") -> CFExplanationResults:\n",
    "    return generate_cf_results(cf_module, dm, params=params, rng_key=rng_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _compute_acc(x: jnp.ndarray, y: jnp.ndarray):\n",
    "    return jnp.sum(x == y) / len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_predictive_acc(cf_results: CFExplanationResults):\n",
    "    pred_fn = cf_results.pred_fn\n",
    "    y_pred = pred_fn(cf_results.X).reshape(-1, 1)\n",
    "    label = cf_results.y.reshape(-1, 1)\n",
    "    return _compute_acc(jnp.round(y_pred), label).item()\n",
    "\n",
    "def compute_validity(cf_results: CFExplanationResults):\n",
    "    pred_fn = cf_results.pred_fn\n",
    "    y_pred = pred_fn(cf_results.X).reshape(-1, 1).round()\n",
    "    y_prime = 1 - y_pred\n",
    "    cf_y = pred_fn(cf_results.cfs).reshape(-1, 1).round()\n",
    "    return _compute_acc(y_prime, cf_y).item()\n",
    "\n",
    "def compute_proximity(cf_results: CFExplanationResults):\n",
    "    return jnp.abs(cf_results.X - cf_results.cfs).sum(axis=1).mean().item()\n",
    "\n",
    "def get_runtime(cf_results: CFExplanationResults):\n",
    "    return cf_results.total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "metrics2fn = {\n",
    "    \"acc\": compute_predictive_acc,\n",
    "    \"validity\": compute_validity,\n",
    "    \"proximity\": compute_proximity,\n",
    "    \"runtime\": get_runtime\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DEFAULT_METRICS = ['acc', 'validity', 'proximity']\n",
    "\n",
    "def evaluate_cfs(cf_results: CFExplanationResults,\n",
    "                 metrics: Optional[List[str]] = None,\n",
    "                 return_dict: bool = True,\n",
    "                 return_df: bool = False):\n",
    "    cf_name = cf_results.cf_name\n",
    "    result_dict = {\n",
    "        cf_name: dict()\n",
    "    }\n",
    "    if metrics is None:\n",
    "        metrics = DEFAULT_METRICS\n",
    "\n",
    "    for metric in metrics:\n",
    "        result_dict[cf_name][metric] = metrics2fn[metric](cf_results)\n",
    "    result_df = pd.DataFrame.from_dict(result_dict, orient='index')\n",
    "    if return_dict and return_df:\n",
    "        return (result_dict, result_df)\n",
    "    elif return_dict or return_df:\n",
    "        return result_df if return_df else result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def benchmark_cfs(cf_results_list: Iterable[CFExplanationResults],\n",
    "                  metrics: Optional[List[str]] = None):\n",
    "    dfs = [\n",
    "        evaluate_cfs(cf_results=cf_results, metrics=metrics, return_dict=False, return_df=True)\n",
    "            for cf_results in cf_results_list\n",
    "    ]\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VanillaCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_configs = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    \"batch_size\": 256,\n",
    "    'sample_frac': 0.1,\n",
    "    \"continous_cols\": [\n",
    "        \"age\",\n",
    "        \"hours_per_week\"\n",
    "    ],\n",
    "    \"discret_cols\": [\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"marital_status\",\n",
    "        \"occupation\",\n",
    "        \"race\",\n",
    "        \"gender\"\n",
    "    ],\n",
    "}\n",
    "m_configs = {\n",
    "    \"sizes\": [50, 10, 50],\n",
    "    'lr': 0.003,\n",
    "    \"dropout_rate\": 0.3\n",
    "}\n",
    "t_configs = {\n",
    "    'n_epochs': 20,\n",
    "    'monitor_metrics': 'val/val_loss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "Epoch 19: 100%|██████████| 10/10 [00:00<00:00, 62.79batch/s, train/train_loss_1=0.0653]\n"
     ]
    }
   ],
   "source": [
    "from cfnet.training_module import PredictiveTrainingModule\n",
    "\n",
    "training_module = PredictiveTrainingModule(m_configs)\n",
    "dm = TabularDataModule(data_configs)\n",
    "\n",
    "params, opt_state = train_model(\n",
    "    training_module, \n",
    "    dm, \n",
    "    t_configs\n",
    ")\n",
    "pred_fn = lambda x: training_module.forward(params, random.PRNGKey(0), x, is_training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 153.05it/s]\n"
     ]
    }
   ],
   "source": [
    "cf_exp = VanillaCF({ \"n_steps\": 1000, 'pred_fn': pred_fn })\n",
    "cf_res = generate_cf_results_local_exp(cf_exp, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7997788786888123"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_validity(cf_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>validity</th>\n",
       "      <th>proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VanillaCF</th>\n",
       "      <td>0.822012</td>\n",
       "      <td>0.799779</td>\n",
       "      <td>6.929937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc  validity  proximity\n",
       "VanillaCF  0.822012  0.799779   6.929937"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cfs(\n",
    "    cf_res, return_df=True\n",
    ")[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CounterNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_configs = {\n",
    "    \"enc_sizes\": [50,10],\n",
    "    \"dec_sizes\": [10],\n",
    "    \"exp_sizes\": [50, 50],\n",
    "    \"dropout_rate\": 0.3,    \n",
    "    'lr': 0.003,\n",
    "    \"lambda_1\": 1.0,\n",
    "    \"lambda_3\": 0.1,\n",
    "    \"lambda_2\": 0.2,\n",
    "}\n",
    "t_configs = {\n",
    "    'n_epochs': 100,\n",
    "    'monitor_metrics': 'val/val_loss'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 10/10 [00:00<00:00, 64.40batch/s, train/train_loss_1=0.0485, train/train_loss_2=0.000302, train/train_loss_3=0.105]\n"
     ]
    }
   ],
   "source": [
    "from cfnet.training_module import CounterNetTrainingModule\n",
    "\n",
    "cfnet = CounterNetTrainingModule(m_configs)\n",
    "dm = TabularDataModule(data_configs)\n",
    "\n",
    "params, opt_state = train_model(\n",
    "    cfnet, dm, \n",
    "    t_configs\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_res = generate_cf_results(cfnet, dm, params, random.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>validity</th>\n",
       "      <th>proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CounterNet</th>\n",
       "      <td>0.81931</td>\n",
       "      <td>0.997912</td>\n",
       "      <td>6.497492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                acc  validity  proximity\n",
       "CounterNet  0.81931  0.997912   6.497492"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cfs(\n",
    "    cf_res, return_df=True\n",
    ")[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
