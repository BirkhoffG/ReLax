{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Module\n",
    "\n",
    "> `DataModule` for training parametric models, generating and benchmarking CF explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data.module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from relax.utils import show_doc\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "show_doc_parser = show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.utils import load_json, validate_configs, cat_normalize\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.utils.validation import check_is_fitted, NotFittedError\n",
    "from urllib.request import urlretrieve\n",
    "from relax.data.loader import Dataset, ArrayDataset, DataLoader, DataloaderBackends\n",
    "from pydantic.fields import ModelField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from fastcore.test import *\n",
    "from copy import deepcopy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Module Interfaces\n",
    "\n",
    "High-level interfaces for `DataModule`. Docs to be added. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseDataModule(ABC):\n",
    "    \"\"\"DataModule Interface\"\"\"\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def data_name(self) -> str: \n",
    "        return\n",
    "        \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def data(self) -> Any:\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def train_dataset(self) -> Dataset:\n",
    "        return\n",
    "    \n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def val_dataset(self) -> Dataset:\n",
    "        return\n",
    "\n",
    "    @property\n",
    "    @abstractmethod\n",
    "    def test_dataset(self) -> Dataset:\n",
    "        return\n",
    "\n",
    "    def dataset(self, name: str) -> Dataset:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self, batch_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def val_dataloader(self, batch_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def test_dataloader(self, batch_size):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def prepare_data(self) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, data) -> jnp.DeviceArray:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def inverse_transform(self, x: jnp.DeviceArray) -> Any:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def apply_constraints(\n",
    "        self, \n",
    "        x: jnp.DeviceArray,\n",
    "        cf: jnp.DeviceArray,\n",
    "        hard: bool\n",
    "    ) -> jnp.DeviceArray:\n",
    "        return cf\n",
    "    \n",
    "    def apply_regularization(\n",
    "        self, \n",
    "        x: jnp.DeviceArray,\n",
    "        cf: jnp.DeviceArray,\n",
    "        hard: bool\n",
    "    ):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabula Data Module\n",
    "\n",
    "`DataModule` for processing tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "def find_imutable_idx_list(\n",
    "    imutable_col_names: List[str],\n",
    "    discrete_col_names: List[str],\n",
    "    continuous_col_names: List[str],\n",
    "    cat_arrays: List[List[str]],\n",
    ") -> List[int]:\n",
    "    imutable_idx_list = []\n",
    "    for idx, col_name in enumerate(continuous_col_names):\n",
    "        if col_name in imutable_col_names:\n",
    "            imutable_idx_list.append(idx)\n",
    "\n",
    "    cat_idx = len(continuous_col_names)\n",
    "\n",
    "    for i, (col_name, cols) in enumerate(zip(discrete_col_names, cat_arrays)):\n",
    "        cat_end_idx = cat_idx + len(cols)\n",
    "        if col_name in imutable_col_names:\n",
    "            imutable_idx_list += list(range(cat_idx, cat_end_idx))\n",
    "        cat_idx = cat_end_idx\n",
    "    return imutable_idx_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TransformerMixinType(TransformerMixin):\n",
    "    @classmethod\n",
    "    def __get_validators__(cls):\n",
    "        yield cls.validate\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, v):\n",
    "        if not isinstance(v, TransformerMixin):\n",
    "            raise TypeError(\"`sklearn.base.TransformerMixin` required\")\n",
    "        return v\n",
    "    \n",
    "    @classmethod\n",
    "    def __modify_schema__(\n",
    "        cls, field_schema: Dict[str, Any], field: Optional[ModelField]\n",
    "    ):\n",
    "        if field:\n",
    "            field_schema['type'] = 'TransformerMixin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _supported_backends(): \n",
    "    back = DataloaderBackends()\n",
    "    return back.supported()\n",
    "\n",
    "class TabularDataModuleConfigs(BaseParser):\n",
    "    \"\"\"Configurator of `TabularDataModule`.\"\"\"\n",
    "\n",
    "    data_dir: str = Field(description=\"The directory of dataset.\")\n",
    "    data_name: str = Field(description=\"The name of `TabularDataModule`.\")\n",
    "    continous_cols: List[str] = Field(\n",
    "        [], description=\"Continuous features/columns in the data.\"\n",
    "    )\n",
    "    discret_cols: List[str] = Field(\n",
    "        [], description=\"Categorical features/columns in the data.\"\n",
    "    )\n",
    "    imutable_cols: List[str] = Field(\n",
    "        [], description=\"Immutable features/columns in the data.\"\n",
    "    )\n",
    "    normalizer: Optional[TransformerMixinType] = Field(\n",
    "        default_factory=lambda: MinMaxScaler(),\n",
    "        description=\"Sklearn scalar for continuous features. Can be unfitted, fitted, or None. \"\n",
    "        \"If not fitted, the `TabularDataModule` will fit using the training data. If fitted, no fitting will be applied. \"\n",
    "        \"If `None`, no transformation will be applied. Default to `MinMaxScaler()`.\"\n",
    "    )\n",
    "    encoder: Optional[TransformerMixinType] = Field(\n",
    "        default_factory=lambda: OneHotEncoder(sparse=False),\n",
    "        description=\"Fitted encoder for categorical features. Can be unfitted, fitted, or None. \"\n",
    "        \"If not fitted, the `TabularDataModule` will fit using the training data. If fitted, no fitting will be applied. \"\n",
    "        \"If `None`, no transformation will be applied. Default to `OneHotEncoder(sparse=False)`.\"\n",
    "    )\n",
    "    sample_frac: Optional[float] = Field(\n",
    "        None, description=\"Sample fraction of the data. Default to use the entire data.\", \n",
    "        ge=0., le=1.0\n",
    "    )\n",
    "    backend: str = Field(\n",
    "        \"jax\", description=f\"`Dataloader` backend. Currently supports: {_supported_backends()}\"\n",
    "    )\n",
    "\n",
    "    class Config:\n",
    "        json_encoders = {\n",
    "            TransformerMixinType: lambda v: f\"{v.__class__.__name__}()\",\n",
    "        }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example configurator of the **adult** dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_dict = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    \"continous_cols\": [\"age\", \"hours_per_week\"],\n",
    "    \"discret_cols\": [\"workclass\", \"education\", \"marital_status\",\"occupation\"],\n",
    "    \"imutable_cols\": [\"age\", \"workclass\", \"marital_status\"],\n",
    "    \"normalizer\": MinMaxScaler(),\n",
    "    \"encoder\": OneHotEncoder(sparse=False),\n",
    "    \"sample_frac\": 0.1,\n",
    "    \"backend\": \"jax\"\n",
    "}\n",
    "configs = TabularDataModuleConfigs(**configs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _check_cols(data: pd.DataFrame, configs: TabularDataModuleConfigs) -> pd.DataFrame:\n",
    "    data = data.astype({\n",
    "        col: float for col in configs.continous_cols\n",
    "    })\n",
    "    \n",
    "    cols = configs.continous_cols + configs.discret_cols\n",
    "    # check target columns\n",
    "    target_col = data.columns[-1]\n",
    "    assert not target_col in cols, \\\n",
    "        f\"continous_cols or discret_cols contains target_col={target_col}.\"\n",
    "    \n",
    "    # check imutable cols\n",
    "    for col in configs.imutable_cols:\n",
    "        assert col in cols, \\\n",
    "            f\"imutable_cols=[{col}] is not specified in `continous_cols` or `discret_cols`.\"\n",
    "    data = data[cols + [target_col]]\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _process_data(\n",
    "    df: pd.DataFrame | None, configs: TabularDataModuleConfigs\n",
    ") -> pd.DataFrame:\n",
    "    if df is None:\n",
    "        df = pd.read_csv(configs.data_dir)\n",
    "    elif isinstance(df, pd.DataFrame):\n",
    "        df = df\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"{type(df).__name__} is not supported as an input type for `TabularDataModule`.\")\n",
    "\n",
    "    df = _check_cols(df, configs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "df_1 = _process_data(None, configs)\n",
    "_df_t = pd.read_csv(configs.data_dir)\n",
    "df_2 = _process_data(_df_t, configs)\n",
    "assert pd.DataFrame.equals(df_1, df_2)\n",
    "\n",
    "_config_fail = deepcopy(configs)\n",
    "_config_fail.data_dir = \"assets/data/s_adult_1.csv\" # wrong data path\n",
    "test_fail(lambda: _process_data(None, _config_fail), contains=\"No such file or directory\")\n",
    "test_fail(lambda: _process_data(\"fail\", configs), contains=\"not supported as an input type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _transform_df(\n",
    "    transformer: TransformerMixin | None,\n",
    "    data: pd.DataFrame,\n",
    "    cols: List[str] | None,\n",
    "):\n",
    "    if transformer is None:\n",
    "        return data[cols].to_numpy() if cols else np.array([[] for _ in range(len(data))])\n",
    "    else:\n",
    "        return (\n",
    "            transformer.transform(data[cols])\n",
    "                if cols else np.array([[] for _ in range(len(data))])\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test\n",
    "df = pd.read_csv('assets/data/s_adult.csv')\n",
    "cols = ['age', 'hours_per_week']\n",
    "sca = MinMaxScaler().fit(df[cols])\n",
    "x = _transform_df(sca, df, cols)\n",
    "assert x.shape == (len(df), len(cols))\n",
    "\n",
    "cols = []\n",
    "sca = MinMaxScaler()\n",
    "x = _transform_df(sca, df, cols)\n",
    "assert x.shape == (len(df), len(cols))\n",
    "\n",
    "cols = None\n",
    "sca = MinMaxScaler()\n",
    "x = _transform_df(sca, df, cols)\n",
    "assert x.shape == (len(df), 0)\n",
    "\n",
    "\n",
    "cols = ['age', 'hours_per_week']\n",
    "sca = None\n",
    "x = _transform_df(sca, df, cols)\n",
    "assert np.allclose(x, df[cols].to_numpy())\n",
    "\n",
    "cols = [\"workclass\", \"education\"]\n",
    "enc = OneHotEncoder(sparse=False).fit(df[cols])\n",
    "x = _transform_df(enc, df, cols)\n",
    "assert x.shape == (len(df), enc.categories_[0].shape[0] + enc.categories_[1].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _inverse_transform_np(\n",
    "    transformer: TransformerMixin | None,\n",
    "    x: np.ndarray,\n",
    "    cols: List[str] | None\n",
    "):\n",
    "    assert len(cols) <= x.shape[-1], \\\n",
    "        f\"x.shape={x.shape} probably will not match len(cols)={len(cols)}\"\n",
    "    \n",
    "    if cols:\n",
    "        data = transformer.inverse_transform(x) if transformer else x\n",
    "        df = pd.DataFrame(data=data, columns=cols)\n",
    "    else:\n",
    "        df = None\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test\n",
    "df = pd.read_csv('assets/data/s_adult.csv')\n",
    "cols = ['age', 'hours_per_week']\n",
    "sca = MinMaxScaler().fit(df[cols])\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert np.allclose(df[cols].values, data.values)\n",
    "\n",
    "cols = []\n",
    "sca = MinMaxScaler()\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert data is None\n",
    "\n",
    "cols = ['age', 'hours_per_week']\n",
    "sca = None\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert np.allclose(df[cols].values, data.values)\n",
    "\n",
    "cols = ['workclass', 'education']\n",
    "sca = OneHotEncoder().fit(df[cols])\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape[0] == len(df)\n",
    "assert df[cols].equals(data)\n",
    "\n",
    "cols = []\n",
    "sca = OneHotEncoder()\n",
    "x = _transform_df(sca, df, cols)\n",
    "data = _inverse_transform_np(sca, x, cols)\n",
    "\n",
    "assert x.shape == (len(df), len(cols))\n",
    "assert data is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _init_scalar_encoder(\n",
    "    data: pd.DataFrame,\n",
    "    configs: TabularDataModuleConfigs\n",
    ") -> Dict[str, TransformerMixin | None]: \n",
    "    # The normlizer and encoder will be either None, fitted or not fitted.\n",
    "    # If the user has specified the normlizer and encoder, then we will use it.\n",
    "    # Otherwise, we will fit the normlizer and encoder.\n",
    "    # fit scalar\n",
    "    if configs.normalizer is not None:\n",
    "        scalar = configs.normalizer\n",
    "        try:\n",
    "            check_is_fitted(scalar)\n",
    "        except NotFittedError:\n",
    "            if configs.continous_cols:  scalar.fit(data[configs.continous_cols])\n",
    "            else:                       scalar = None\n",
    "    else:\n",
    "        scalar = None\n",
    "    \n",
    "    if configs.encoder is not None:\n",
    "        encoder = configs.encoder\n",
    "        try:\n",
    "            check_is_fitted(encoder)\n",
    "        except NotFittedError:\n",
    "            if configs.discret_cols:    encoder.fit(data[configs.discret_cols])\n",
    "            else:                       encoder = None\n",
    "    else:\n",
    "        encoder = None\n",
    "    return dict(scalar=scalar, encoder=encoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# test\n",
    "configs_dict = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    \"continous_cols\": [\"age\", \"hours_per_week\"],\n",
    "    \"discret_cols\": [\"workclass\", \"education\", \"marital_status\",\"occupation\"],\n",
    "    \"imutable_cols\": [\"age\", \"workclass\", \"marital_status\"],\n",
    "    \"normalizer\": None,\n",
    "    \"encoder\": OneHotEncoder(),\n",
    "    \"sample_frac\": 0.1,\n",
    "    \"backend\": \"jax\"\n",
    "}\n",
    "configs = TabularDataModuleConfigs(**configs_dict)\n",
    "df = pd.read_csv(configs.data_dir)\n",
    "scalar_and_encoder = _init_scalar_encoder(df, configs)\n",
    "\n",
    "assert scalar_and_encoder[\"scalar\"] is None\n",
    "check_is_fitted(scalar_and_encoder[\"encoder\"])\n",
    "\n",
    "scalar = MinMaxScaler().fit(df[configs.continous_cols].iloc[:100])\n",
    "configs_dict[\"normalizer\"] = deepcopy(scalar)\n",
    "configs = TabularDataModuleConfigs(**configs_dict)\n",
    "scalar_and_encoder = _init_scalar_encoder(df, configs)\n",
    "\n",
    "# check if the scalar is refitted\n",
    "assert np.allclose(\n",
    "    scalar_and_encoder[\"scalar\"].transform(df[configs.continous_cols].iloc[100:200]),\n",
    "    scalar.transform(df[configs.continous_cols].iloc[100:200])\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class TabularDataModule(BaseDataModule):\n",
    "    \"\"\"DataModule for tabular data\"\"\"\n",
    "    cont_scalar = None # scalar for normalizing continuous features\n",
    "    cat_encoder = None # encoder for encoding categorical features\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        data_config: dict | TabularDataModuleConfigs, # Configurator of `TabularDataModule`\n",
    "        data: pd.DataFrame = None # Data in `pd.DataFrame`. If `data` is `None`, the DataModule will load data from `data_dir`.\n",
    "    ):\n",
    "        self._configs: TabularDataModuleConfigs = validate_configs(\n",
    "            data_config, TabularDataModuleConfigs\n",
    "        )\n",
    "        self._data = _process_data(data, self._configs)\n",
    "        # init idx lists\n",
    "        self.cat_idx = len(self._configs.continous_cols)\n",
    "        self._imutable_idx_list = []\n",
    "        self.prepare_data()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        scalar_encoder_dict = _init_scalar_encoder(\n",
    "            data=self._data, configs=self._configs\n",
    "        )\n",
    "        self.cont_scalar = scalar_encoder_dict['scalar']\n",
    "        self.cat_encoder = scalar_encoder_dict['encoder']\n",
    "        X, y = self.transform(self.data)\n",
    "\n",
    "        self._cat_arrays = self.cat_encoder.categories_ \\\n",
    "            if self._configs.discret_cols else []\n",
    "\n",
    "        self._imutable_idx_list = find_imutable_idx_list(\n",
    "            imutable_col_names=self._configs.imutable_cols,\n",
    "            discrete_col_names=self._configs.discret_cols,\n",
    "            continuous_col_names=self._configs.continous_cols,\n",
    "            cat_arrays=self._cat_arrays,\n",
    "        )\n",
    "        \n",
    "        # prepare train & test\n",
    "        train_test_tuple = train_test_split(X, y, shuffle=False)\n",
    "        train_X, test_X, train_y, test_y = map(\n",
    "             lambda x: x.astype(float), train_test_tuple\n",
    "         )\n",
    "        if self._configs.sample_frac:\n",
    "            train_size = int(len(train_X) * self._configs.sample_frac)\n",
    "            train_X, train_y = train_X[:train_size], train_y[:train_size]\n",
    "        \n",
    "        self._train_dataset = ArrayDataset(train_X, train_y)\n",
    "        self._val_dataset = ArrayDataset(test_X, test_y)\n",
    "        self._test_dataset = self.val_dataset\n",
    "\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __setattr__(self, attr: str, val: Any) -> None:\n",
    "        if self.__initialized and attr in (\n",
    "            '_data', 'cat_idx', '_imutable_idx_list', '_cat_arrays',\n",
    "            '_train_dataset', '_val_dataset', '_test_dataset',\n",
    "            'cont_scalar', 'cat_encoder'\n",
    "        ):\n",
    "            raise ValueError(f'{attr} attribute should not be set after '\n",
    "                             f'{self.__class__.__name__} is initialized')\n",
    "\n",
    "        super().__setattr__(attr, val)\n",
    "\n",
    "    @property\n",
    "    def data_name(self) -> str: \n",
    "        return self._configs.data_name\n",
    "    \n",
    "    @property\n",
    "    def data(self) -> pd.DataFrame:\n",
    "        \"\"\"Loaded data in `pd.DataFrame`.\"\"\"\n",
    "        return self._data\n",
    "    \n",
    "    @property\n",
    "    def train_dataset(self) -> ArrayDataset:\n",
    "        return self._train_dataset\n",
    "    \n",
    "    @property\n",
    "    def val_dataset(self) -> ArrayDataset:\n",
    "        return self._val_dataset\n",
    "\n",
    "    @property\n",
    "    def test_dataset(self) -> ArrayDataset:\n",
    "        return self._test_dataset\n",
    "\n",
    "    def dataset(\n",
    "        self, name: str # Name of the dataset; should be one of ['train', 'val', 'test'].\n",
    "    ) -> ArrayDataset:\n",
    "        if name == 'train': return self._train_dataset\n",
    "        elif name == 'val': return self._val_dataset\n",
    "        elif name == 'test': return self._test_dataset\n",
    "        else: raise ValueError(f\"`name` must be one of ['train', 'val', 'test'], but got {name}\")\n",
    "\n",
    "    def train_dataloader(self, batch_size):\n",
    "        return DataLoader(self.train_dataset, self._configs.backend, \n",
    "            batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self, batch_size):\n",
    "        return DataLoader(self.val_dataset, self._configs.backend,\n",
    "            batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self, batch_size):\n",
    "        return DataLoader(self.val_dataset, self._configs.backend,\n",
    "            batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False\n",
    "        )\n",
    "\n",
    "    def transform(\n",
    "        self, \n",
    "        data: pd.DataFrame, # Data to be transformed to `numpy.ndarray`\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]: # Return `(X, y)`\n",
    "        \"\"\"Transform data into numerical representations.\"\"\"\n",
    "        # TODO: validate `data`\n",
    "        X_cont = _transform_df(\n",
    "            self.cont_scalar, data, self._configs.continous_cols\n",
    "        )\n",
    "        X_cat = _transform_df(\n",
    "            self.cat_encoder, data, self._configs.discret_cols\n",
    "        )\n",
    "        X = np.concatenate((X_cont, X_cat), axis=1)\n",
    "        y = data.iloc[:, -1:].to_numpy()\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def inverse_transform(\n",
    "        self, \n",
    "        x: jnp.DeviceArray, # The transformed input to be scaled back\n",
    "        y: jnp.DeviceArray = None # The transformed label to be scaled back. If `None`, the target columns will not be scaled back.\n",
    "    ) -> pd.DataFrame: # Transformed `pd.DataFrame`. \n",
    "        \"\"\"Scaled back into `pd.DataFrame`.\"\"\"\n",
    "        X_cont_df = _inverse_transform_np(\n",
    "            self.cont_scalar, x[:, :self.cat_idx], self._configs.continous_cols\n",
    "        )\n",
    "        X_cat_df = _inverse_transform_np(\n",
    "            self.cat_encoder, x[:, self.cat_idx:], self._configs.discret_cols\n",
    "        )\n",
    "        if y is not None:\n",
    "            y_df = pd.DataFrame(data=y, columns=[self.data.columns[-1]])\n",
    "        else:\n",
    "            y_df = None\n",
    "        \n",
    "        return pd.concat(\n",
    "            [X_cont_df, X_cat_df, y_df], axis=1\n",
    "        )\n",
    "\n",
    "    def apply_constraints(\n",
    "        self, \n",
    "        x: jnp.DeviceArray, # input\n",
    "        cf: jnp.DeviceArray, # Unnormalized counterfactuals\n",
    "        hard: bool = False # Apply hard constraints or not\n",
    "    ) -> jnp.DeviceArray:\n",
    "        \"\"\"Apply categorical normalization and immutability constraints\"\"\"\n",
    "        cf = cat_normalize(\n",
    "            cf, cat_arrays=self._cat_arrays, \n",
    "            cat_idx=len(self._configs.continous_cols),\n",
    "            hard=hard\n",
    "        )\n",
    "        # apply immutable constraints\n",
    "        if len(self._configs.imutable_cols) > 0:\n",
    "            cf = cf.at[:, self._imutable_idx_list].set(x[:, self._imutable_idx_list])\n",
    "        return cf\n",
    "\n",
    "    def apply_regularization(\n",
    "        self, \n",
    "        x: jnp.DeviceArray, # Input\n",
    "        cf: jnp.DeviceArray, # Unnormalized counterfactuals\n",
    "    ) -> float: # Return regularization loss\n",
    "        \"\"\"Apply categorical constraints by adding regularization terms\"\"\"\n",
    "        reg_loss = 0.\n",
    "        cat_idx = len(self._configs.continous_cols)\n",
    "\n",
    "        for col in self._cat_arrays:\n",
    "            cat_idx_end = cat_idx + len(col)\n",
    "            reg_loss += jnp.power(\n",
    "                (jnp.sum(cf[cat_idx:cat_idx_end]) - 1.0), 2\n",
    "            )\n",
    "        return reg_loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load `TabularDataModule` from `TabularDataModuleConfigs`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = TabularDataModuleConfigs(\n",
    "    data_name='adult',\n",
    "    data_dir='assets/data/s_adult.csv',\n",
    "    continous_cols=['age', 'hours_per_week'],\n",
    "    discret_cols=['workclass', 'education', 'marital_status', 'occupation'],\n",
    "    imutable_cols=['age', 'workclass', 'marital_status'],\n",
    "    sample_frac=0.1\n",
    ")\n",
    "\n",
    "dm = TabularDataModule(configs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explicitly pass a `pd.DataFrame` to `TabularDataModule`. \n",
    "In this case, `TabularDataModule` will use the passed `pd.DataFrame`, instead of loading data from `data_dir` in `TabularDataModuleConfigs`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('assets/data/s_adult.csv')[:1000]\n",
    "dm = TabularDataModule(configs, data=df)\n",
    "assert len(dm.data) == 1000 # dm contains `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/relax/tree/master/blob/master/relax/data/module.py#L340){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TABULARDATAMODULE.DATA\n",
       "\n",
       "::: {.doc-sig}\n",
       "\n",
       " relax.data.module.<b>TabularDataModule.data</b> <em>()</em>\n",
       "\n",
       ":::\n",
       "\n",
       "Loaded data in `pd.DataFrame`."
      ],
      "text/plain": [
       "<relax.docs.CustomizedMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabulaDataModule` loads either a csv file (specified in `data_dir` in `data_config`), \n",
    "or directly passes a DataFrame (specified as `data`). \n",
    "Either way, this data needs to satisfy following conditions:\n",
    "\n",
    "* It requires the **target column** (i.e., the labels) to be the **last** column of the DataFrame, \n",
    "and the rest columns are **features**. \n",
    "This **target column** needs to be binary-valued (i.e., it is either `0` or `1`).\n",
    "    * In the belowing example, **income** is the **target column**, and the rest columns are features.\n",
    "* It requires `continous_cols` and `discret_cols` in `data_config` to be subsets of `data.columns`.\n",
    "* It only use columns specified in `continous_cols` and `discret_cols`.\n",
    "    * It loads `continous_cols` first, then `discret_cols`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours_per_week      workclass     education marital_status  \\\n",
       "0  42.0            45.0        Private       HS-grad        Married   \n",
       "1  32.0            40.0  Self-Employed  Some-college        Married   \n",
       "2  35.0            40.0        Private         Assoc         Single   \n",
       "3  36.0            40.0        Private       HS-grad         Single   \n",
       "4  57.0            35.0        Private        School        Married   \n",
       "\n",
       "     occupation  income  \n",
       "0   Blue-Collar       1  \n",
       "1   Blue-Collar       0  \n",
       "2  White-Collar       1  \n",
       "3   Blue-Collar       0  \n",
       "4       Service       0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/relax/tree/master/blob/master/relax/data/module.py#L379){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TABULARDATAMODULE.TRANSFORM\n",
       "\n",
       "::: {.doc-sig}\n",
       "\n",
       " relax.data.module.<b>TabularDataModule.transform</b> <em>(data)</em>\n",
       "\n",
       ":::\n",
       "\n",
       "Transform data into numerical representations.\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "## Parameters:\n",
       "\n",
       "* <b>data</b> (`pd.DataFrame`) -- Data to be transformed to `numpy.ndarray`\n",
       "\n",
       "\n",
       ":::\n",
       "\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "## Returns:\n",
       "\n",
       "&ensp;&ensp;&ensp;&ensp;(`Tuple[np.ndarray, np.ndarray]`) -- Return `(X, y)`\n",
       "\n",
       "\n",
       ":::"
      ],
      "text/plain": [
       "<relax.docs.CustomizedMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, we transform *continuous features* via `MinMaxScaler`, \n",
    "and *discrete features* via `OneHotEncoding`. \n",
    "\n",
    "A tabular data point $x$ is encoded as \n",
    "$$x = [\\underbrace{x_{0}, x_{1}, ..., x_{m}}_{\\text{cont features}}, \n",
    "\\underbrace{x_{m+1}^{c=1},..., x_{m+p}^{c=1}}_{\\text{cat feature} (1)}, ..., \n",
    "\\underbrace{x_{k-q}^{c=i},..., x_{k}^{^{c=i}}}_{\\text{cat feature} (i)}]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dm.data.head()\n",
    "X, y = dm.transform(df)\n",
    "\n",
    "assert isinstance(X, np.ndarray)\n",
    "assert isinstance(y, np.ndarray)\n",
    "assert y.shape == (len(X), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/relax/tree/master/blob/master/relax/data/module.py#L396){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TABULARDATAMODULE.INVERSE_TRANSFORM\n",
       "\n",
       "::: {.doc-sig}\n",
       "\n",
       " relax.data.module.<b>TabularDataModule.inverse_transform</b> <em>(x, y=None)</em>\n",
       "\n",
       ":::\n",
       "\n",
       "Scaled back into `pd.DataFrame`.\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "## Parameters:\n",
       "\n",
       "* <b>x</b> (`jnp.DeviceArray`) -- The transformed input to be scaled back\n",
       "* <b>y</b> (`jnp.DeviceArray`, <em>default=None</em>) -- The transformed label to be scaled back. If `None`, the target columns will not be scaled back.\n",
       "\n",
       "\n",
       ":::\n",
       "\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "## Returns:\n",
       "\n",
       "&ensp;&ensp;&ensp;&ensp;(`pd.DataFrame`) -- Transformed `pd.DataFrame`.\n",
       "\n",
       "\n",
       ":::"
      ],
      "text/plain": [
       "<relax.docs.CustomizedMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.inverse_transform)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabularDataModule.inverse_transform` scales numerical representations back\n",
    "to the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours_per_week      workclass     education marital_status  \\\n",
       "0  42.0            45.0        Private       HS-grad        Married   \n",
       "1  32.0            40.0  Self-Employed  Some-college        Married   \n",
       "2  35.0            40.0        Private         Assoc         Single   \n",
       "3  36.0            40.0        Private       HS-grad         Single   \n",
       "4  57.0            35.0        Private        School        Married   \n",
       "\n",
       "     occupation  income  \n",
       "0   Blue-Collar       1  \n",
       "1   Blue-Collar       0  \n",
       "2  White-Collar       1  \n",
       "3   Blue-Collar       0  \n",
       "4       Service       0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.inverse_transform(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `y` is not passed, it will only scale back `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Assoc</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Blue-Collar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Service</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hours_per_week      workclass     education marital_status  \\\n",
       "0  42.0            45.0        Private       HS-grad        Married   \n",
       "1  32.0            40.0  Self-Employed  Some-college        Married   \n",
       "2  35.0            40.0        Private         Assoc         Single   \n",
       "3  36.0            40.0        Private       HS-grad         Single   \n",
       "4  57.0            35.0        Private        School        Married   \n",
       "\n",
       "     occupation  \n",
       "0   Blue-Collar  \n",
       "1   Blue-Collar  \n",
       "2  White-Collar  \n",
       "3   Blue-Collar  \n",
       "4       Service  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/relax/tree/master/blob/master/relax/data/module.py#L417){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TABULARDATAMODULE.APPLY_CONSTRAINTS\n",
       "\n",
       "::: {.doc-sig}\n",
       "\n",
       " relax.data.module.<b>TabularDataModule.apply_constraints</b> <em>(x, cf, hard=False)</em>\n",
       "\n",
       ":::\n",
       "\n",
       "Apply categorical normalization and immutability constraints\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "## Parameters:\n",
       "\n",
       "* <b>x</b> (`jnp.DeviceArray`) -- input\n",
       "* <b>cf</b> (`jnp.DeviceArray`) -- Unnormalized counterfactuals\n",
       "* <b>hard</b> (`bool`, <em>default=False</em>) -- Apply hard constraints or not\n",
       "\n",
       "\n",
       ":::\n",
       "\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "## Returns:\n",
       "\n",
       "&ensp;&ensp;&ensp;&ensp;(`jnp.DeviceArray`)\n",
       "\n",
       "\n",
       ":::"
      ],
      "text/plain": [
       "<relax.docs.CustomizedMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.apply_constraints)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TabularDataModule.apply_constraints` does two things: \n",
    "\n",
    "1. It ensures that generated counterfactuals respect the one-hot encoding format (i.e., $\\sum_{p \\to q} x^{c=i}_{p} = 1$).\n",
    "2. It ensures the immutability constraints (i.e., immutable features defined in `imutable_cols` will not be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dm.test_dataloader(batch_size=128)))\n",
    "# unnormalized counterfactuals\n",
    "cf = random.normal(\n",
    "    random.PRNGKey(0), x.shape\n",
    ")\n",
    "# normalized counterfactuals\n",
    "cf_normed = dm.apply_constraints(x, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/relax/tree/master/blob/master/relax/data/module.py#L434){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TABULARDATAMODULE.APPLY_REGULARIZATION\n",
       "\n",
       "::: {.doc-sig}\n",
       "\n",
       " relax.data.module.<b>TabularDataModule.apply_regularization</b> <em>(x, cf)</em>\n",
       "\n",
       ":::\n",
       "\n",
       "Apply categorical constraints by adding regularization terms\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "## Parameters:\n",
       "\n",
       "* <b>x</b> (`jnp.DeviceArray`) -- Input\n",
       "* <b>cf</b> (`jnp.DeviceArray`) -- Unnormalized counterfactuals\n",
       "\n",
       "\n",
       ":::\n",
       "\n",
       "\n",
       "::: {#docs .callout-note icon=false}\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "## Returns:\n",
       "\n",
       "&ensp;&ensp;&ensp;&ensp;(`float`) -- Return regularization loss\n",
       "\n",
       "\n",
       ":::"
      ],
      "text/plain": [
       "<relax.docs.CustomizedMarkdownRenderer>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(TabularDataModule.apply_regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dm.test_dataloader(batch_size=128)))\n",
    "# unnormalized counterfactuals\n",
    "cf = random.normal(\n",
    "    random.PRNGKey(0), x.shape\n",
    ")\n",
    "# normalized counterfactuals\n",
    "cf_normed = dm.apply_constraints(x, cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def sample(datamodule: BaseDataModule, frac: float = 1.0): \n",
    "    X, y = datamodule.train_dataset[:]\n",
    "    size = int(len(X) * frac)\n",
    "    return X[:size], y[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def check_datamodule(dm: TabularDataModule, data_configs: dict | TabularDataModuleConfigs):\n",
    "    batch_size = 32\n",
    "    data_configs = validate_configs(data_configs, TabularDataModuleConfigs)\n",
    "    cat_idx = len(data_configs.continous_cols)\n",
    "    n_cat_feat = len(data_configs.discret_cols)\n",
    "\n",
    "    feats, label = dm.train_dataset[:]\n",
    "    assert feats.shape[0] == len(label)\n",
    "    assert label.shape == (feats.shape[0], 1)\n",
    "\n",
    "    X, y = dm.val_dataset[:]\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    X, y = dm.test_dataset[:]\n",
    "    assert X.shape[0] == len(y)\n",
    "\n",
    "    dl = dm.train_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    assert x.shape[0] == batch_size\n",
    "\n",
    "    dl = dm.val_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    assert x.shape[0] == batch_size\n",
    "\n",
    "    dl = dm.test_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    assert x.shape[0] == batch_size\n",
    "\n",
    "    ############################################################\n",
    "    # test `transform` and `inverse_transform`\n",
    "    ############################################################\n",
    "    df = dm.inverse_transform(feats, label)\n",
    "    assert len(df) == len(feats)\n",
    "    assert len(df.columns) == cat_idx + n_cat_feat + 1\n",
    "\n",
    "    X_transformed, y = dm.transform(df)\n",
    "    assert np.allclose(feats, X_transformed)\n",
    "    assert np.allclose(y, label)\n",
    "    \n",
    "    ############################################################\n",
    "    # test `apply_constraints` ad `project`\n",
    "    ##########################################################\n",
    "    dl = dm.test_dataloader(batch_size)\n",
    "    x, y = next(iter(dl))\n",
    "    cf = random.normal(\n",
    "        random.PRNGKey(0), x.shape\n",
    "    )\n",
    "    cf = dm.apply_constraints(x, cf, hard=False)\n",
    "    assert jnp.allclose(jnp.sum(cf[:, cat_idx:]), len(cf) * n_cat_feat)\n",
    "\n",
    "    cf = dm.apply_constraints(x, cf, hard=True)\n",
    "    assert jnp.count_nonzero(cf == 1) == len(cf) * n_cat_feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "data_configs = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    'sample_frac': 0.1,\n",
    "    \"continous_cols\": [\"age\", \"hours_per_week\"],\n",
    "    \"discret_cols\": [\n",
    "        \"workclass\", \"education\", \"marital_status\",\n",
    "        \"occupation\", \"race\", \"gender\"\n",
    "    ],\n",
    "}\n",
    "dm = TabularDataModule(data_configs)\n",
    "check_datamodule(dm, data_configs)\n",
    "\n",
    "# immutable\n",
    "_data_configs = deepcopy(data_configs)\n",
    "_data_configs[\"imutable_cols\"] = [\"race\",\"gender\"]\n",
    "dm = TabularDataModule(_data_configs)\n",
    "check_datamodule(dm, _data_configs)\n",
    "\n",
    "# no cont\n",
    "_data_configs = deepcopy(data_configs)\n",
    "_data_configs['continous_cols'] = []\n",
    "dm = TabularDataModule(_data_configs)\n",
    "check_datamodule(dm, _data_configs)\n",
    "\n",
    "# no cat\n",
    "_data_configs = deepcopy(data_configs)\n",
    "_data_configs['discret_cols'] = []\n",
    "dm = TabularDataModule(_data_configs)\n",
    "check_datamodule(dm, _data_configs)\n",
    "\n",
    "# https://github.com/BirkhoffG/ReLax/issues/134\n",
    "data_configs = load_json('assets/configs/data_configs/breast_cancer.json')['data_configs']\n",
    "dm = TabularDataModule(data_configs)\n",
    "check_datamodule(dm, data_configs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "DEFAULT_DATA_CONFIGS = {\n",
    "    'adult': {\n",
    "        'data' :'assets/adult/data.csv',\n",
    "        'conf' :'assets/adult/configs.json',\n",
    "        'model' :'assets/adult/model'\n",
    "    },\n",
    "    'heloc': {\n",
    "        'data': 'assets/heloc/data.csv',\n",
    "        'conf': 'assets/heloc/configs.json',\n",
    "        'model' :'assets/heloc/model'\n",
    "    },\n",
    "    'oulad': {\n",
    "        'data': 'assets/oulad/data.csv',\n",
    "        'conf': 'assets/oulad/configs.json',\n",
    "        'model' :'assets/oulad/model'\n",
    "    },\n",
    "    'credit': {\n",
    "        'data': 'assets/credit/data.csv',\n",
    "        'conf': 'assets/credit/configs.json',\n",
    "        'model' :'assets/credit/model'\n",
    "    },\n",
    "    'cancer': {\n",
    "        'data': 'assets/cancer/data.csv',\n",
    "        'conf': 'assets/cancer/configs.json',\n",
    "        'model' :'assets/cancer/model'\n",
    "    },\n",
    "    'student_performance': {\n",
    "        'data': 'assets/student_performance/data.csv',\n",
    "        'conf': 'assets/student_performance/configs.json',\n",
    "        'model' :'assets/student_performance/model'\n",
    "    },\n",
    "    'titanic': {\n",
    "        'data': 'assets/titanic/data.csv',\n",
    "        'conf': 'assets/titanic/configs.json',\n",
    "        'model' :'assets/titanic/model'\n",
    "    },\n",
    "    'german': {\n",
    "        'data': 'assets/german/data.csv',\n",
    "        'conf': 'assets/german/configs.json',\n",
    "        'model' :'assets/german/model'\n",
    "    },\n",
    "    'spam': {\n",
    "        'data': 'assets/spam/data.csv',\n",
    "        'conf': 'assets/spam/configs.json',\n",
    "        'model' :'assets/spam/model'\n",
    "    },\n",
    "    'ozone': {\n",
    "        'data': 'assets/ozone/data.csv',\n",
    "        'conf': 'assets/ozone/configs.json',\n",
    "        'model' :'assets/ozone/model'\n",
    "    },\n",
    "    'qsar': {\n",
    "        'data': 'assets/qsar/data.csv',\n",
    "        'conf': 'assets/qsar/configs.json',\n",
    "        'model' :'assets/qsar/model'\n",
    "    },\n",
    "    'bioresponse': {\n",
    "        'data': 'assets/bioresponse/data.csv',\n",
    "        'conf': 'assets/bioresponse/configs.json',\n",
    "        'model' :'assets/bioresponse/model'\n",
    "    },\n",
    "    'churn': {\n",
    "        'data': 'assets/churn/data.csv',\n",
    "        'conf': 'assets/churn/configs.json',\n",
    "        'model' :'assets/churn/model'\n",
    "    },\n",
    "    'road': {\n",
    "        'data': 'assets/road/data.csv',\n",
    "        'conf': 'assets/road/configs.json',\n",
    "        'model' :'assets/road/model'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _validate_dataname(data_name: str):\n",
    "    if data_name not in DEFAULT_DATA_CONFIGS.keys():\n",
    "        raise ValueError(f'`data_name` must be one of {DEFAULT_DATA_CONFIGS.keys()}, '\n",
    "            f'but got data_name={data_name}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_data(\n",
    "    data_name: str, # The name of data\n",
    "    return_config: bool = False, # Return `data_config `or not\n",
    "    data_configs: dict = None # Data configs to override default configuration\n",
    ") -> TabularDataModule | Tuple[TabularDataModule, TabularDataModuleConfigs]: \n",
    "    \"\"\"High-level util function for loading `data` and `data_config`.\"\"\"\n",
    "    \n",
    "    _validate_dataname(data_name)\n",
    "\n",
    "    # get data/config/model urls\n",
    "    _data_path = DEFAULT_DATA_CONFIGS[data_name]['data']\n",
    "    _conf_path = DEFAULT_DATA_CONFIGS[data_name]['conf']\n",
    "    _model_path = DEFAULT_DATA_CONFIGS[data_name]['model']\n",
    "    \n",
    "    data_url = f\"https://github.com/BirkhoffG/ReLax/raw/master/{_data_path}\"\n",
    "    conf_url = f\"https://github.com/BirkhoffG/ReLax/raw/master/{_conf_path}\"\n",
    "    model_params_url = f\"https://github.com/BirkhoffG/ReLax/raw/master/{_model_path}/params.npy\"\n",
    "    model_tree_url = f\"https://github.com/BirkhoffG/ReLax/raw/master/{_model_path}/tree.pkl\"\n",
    "\n",
    "    # create new dir\n",
    "    data_dir = Path(os.getcwd()) / \"cf_data\"\n",
    "    if not data_dir.exists():\n",
    "        os.makedirs(data_dir)\n",
    "    data_path = data_dir / data_name / 'data.csv'\n",
    "    conf_path = data_dir / data_name / 'configs.json'\n",
    "    model_path = data_dir / data_name / \"model\"\n",
    "    if not model_path.exists():\n",
    "        os.makedirs(model_path)\n",
    "\n",
    "    # download data/configs and trained model\n",
    "    if not data_path.is_file():\n",
    "        urlretrieve(data_url, data_path)    \n",
    "    if not conf_path.is_file():\n",
    "        urlretrieve(conf_url, conf_path)\n",
    "    params_path = os.path.join(model_path, \"params.npy\")\n",
    "    tree_path = os.path.join(model_path, \"tree.pkl\")\n",
    "    if not (os.path.isfile(params_path) and os.path.isfile(tree_path)):\n",
    "        urlretrieve(model_params_url, params_path)\n",
    "        urlretrieve(model_tree_url, tree_path)\n",
    "\n",
    "    # read config\n",
    "    config = load_json(conf_path)['data_configs']\n",
    "    config['data_dir'] = str(data_path)\n",
    "\n",
    "    if not (data_configs is None):\n",
    "        config.update(data_configs)\n",
    "\n",
    "    config = TabularDataModuleConfigs(**config)\n",
    "    data_module = TabularDataModule(config)\n",
    "\n",
    "    if return_config:\n",
    "        return data_module, config\n",
    "    else:\n",
    "        return data_module\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_data` easily loads example datasets by passing the `data_name`. \n",
    "For example, you can load the [adult](https://archive.ics.uci.edu/ml/datasets/adult) as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data(data_name = 'adult')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Underlying, `load_data` loads the default `data_configs`. To access this `data_configs`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm, data_configs = load_data(data_name = 'adult', return_config=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to override some of the data configs, \n",
    "you can pass it as an auxillary argumenet in `data_configs`. \n",
    "For example, if you want to use only 10% of the data, you can"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data(\n",
    "    data_name = 'adult', data_configs={'sample_frac': 0.1}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supported Datasets\n",
    "\n",
    "`load_data` currently supports following datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Cont Features</th>\n",
       "      <th># Cat Features</th>\n",
       "      <th># of Data Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>32561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heloc</th>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>10459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oulad</th>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>32593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit</th>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student_performance</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>titanic</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>4601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ozone</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>2534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsar</th>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bioresponse</th>\n",
       "      <td>1776</td>\n",
       "      <td>0</td>\n",
       "      <td>3751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>7043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>road</th>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>111762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     # Cont Features  # Cat Features  # of Data Points\n",
       "adult                              2               6             32561\n",
       "heloc                             21               2             10459\n",
       "oulad                             23               8             32593\n",
       "credit                            20               3             30000\n",
       "cancer                            30               0               569\n",
       "student_performance                2              14               649\n",
       "titanic                            2              24               891\n",
       "german                             7              13              1000\n",
       "spam                              57               0              4601\n",
       "ozone                             72               0              2534\n",
       "qsar                              38               3              1055\n",
       "bioresponse                     1776               0              3751\n",
       "churn                              3              16              7043\n",
       "road                              29               3            111762"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|echo: false\n",
    "def display_data_attrbutes(names: list):\n",
    "    attrs = {\n",
    "        '# Cont Features': { data_name: 0 for data_name in names}, \n",
    "        '# Cat Features': { data_name: 0 for data_name in names},\n",
    "        '# of Data Points': { data_name: 0 for data_name in names}, \n",
    "    }\n",
    "    for data_name in names:\n",
    "        dm, config = load_data(data_name, return_config=True)\n",
    "        attrs['# Cont Features'][data_name] = len(config.continous_cols)\n",
    "        attrs['# Cat Features'][data_name] = len(config.discret_cols)\n",
    "        attrs['# of Data Points'][data_name] = len(dm.data)\n",
    "\n",
    "        # run tests\n",
    "        check_datamodule(dm, config)\n",
    "    return pd.DataFrame.from_dict(attrs)\n",
    "\n",
    "display_data_attrbutes(DEFAULT_DATA_CONFIGS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['adult', 'heloc', 'oulad', 'credit', 'cancer', 'student_performance', 'titanic', 'german', 'spam', 'ozone', 'qsar', 'bioresponse', 'churn', 'road'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_DATA_CONFIGS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "for data_name in DEFAULT_DATA_CONFIGS.keys():\n",
    "    dm, config = load_data(\n",
    "        data_name, return_config=True, data_configs=dict(sample_frac=0.1)\n",
    "    )\n",
    "    assert config.sample_frac == 0.1\n",
    "    check_datamodule(dm, config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
