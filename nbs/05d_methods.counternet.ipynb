{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CounterNet\n",
    "\n",
    "> A prediction-aware recourse model\n",
    "\n",
    "* Paper link: https://arxiv.org/abs/2109.07557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods.counternet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from nbdev import show_doc\n",
    "from relax.utils import show_doc as show_doc_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.module import MLP, BaseTrainingModule\n",
    "from relax.methods.base import BaseCFModule, BaseParametricCFModule, BasePredFnCFModule\n",
    "from relax.trainer import TrainingConfigs, train_model\n",
    "from relax.data import TabularDataModule\n",
    "from relax.utils import validate_configs, sigmoid, accuracy, proximity, make_model, init_net_opt, grad_update\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CounterNet Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class CounterNetModelConfigs(BaseParser):\n",
    "    \"\"\"Configurator of `CounterNetModel`.\"\"\"\n",
    "\n",
    "    enc_sizes: List[int] = Field(description='Encoder sizes.')\n",
    "    dec_sizes: List[int] = Field(description='Predictor sizes.')\n",
    "    exp_sizes: List[int] = Field(description='CF generator sizes.')\n",
    "    dropout_rate: float = Field(0.3, description='Dropout rate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "class CounterNetModel(hk.Module):\n",
    "    \"\"\"CounterNet Model\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        m_config: Dict | CounterNetModelConfigs,  # Model configs which contain configs in `CounterNetModelConfigs`.\n",
    "        name: str = None,  # Name of the module.\n",
    "    ):\n",
    "        \"\"\"CounterNet model architecture.\"\"\"\n",
    "        super().__init__(name=name)\n",
    "        self.configs = validate_configs(m_config, CounterNetModelConfigs)\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray, is_training: bool = True) -> jnp.ndarray:\n",
    "        input_shape = x.shape[-1]\n",
    "        # encoder\n",
    "        z = MLP(self.configs.enc_sizes, self.configs.dropout_rate, name=\"Encoder\")(\n",
    "            x, is_training\n",
    "        )\n",
    "\n",
    "        # prediction\n",
    "        pred = MLP(self.configs.dec_sizes, self.configs.dropout_rate, name=\"Predictor\")(\n",
    "            z, is_training\n",
    "        )\n",
    "        y_hat = hk.Linear(1, name=\"Predictor\")(pred)\n",
    "        y_hat = jax.nn.sigmoid(y_hat)\n",
    "\n",
    "        # explain\n",
    "        z_exp = jnp.concatenate((z, pred), axis=-1)\n",
    "        cf = MLP(self.configs.exp_sizes, self.configs.dropout_rate, name=\"Explainer\")(\n",
    "            z_exp, is_training\n",
    "        )\n",
    "        cf = hk.Linear(input_shape, name=\"Explainer\")(cf)\n",
    "        return y_hat, cf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/nets.py#L80){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CounterNetModelConfigs\n",
       "\n",
       ">      CounterNetModelConfigs (enc_sizes:List[int], dec_sizes:List[int],\n",
       ">                              exp_sizes:List[int], dropout_rate:float=0.3)\n",
       "\n",
       "Configurator of `CounterNetModel`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| enc_sizes | List[int] |  | Encoder sizes. |\n",
       "| dec_sizes | List[int] |  | Predictor sizes. |\n",
       "| exp_sizes | List[int] |  | CF generator sizes. |\n",
       "| dropout_rate | float | 0.3 | Dropout rate. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/nets.py#L80){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CounterNetModelConfigs\n",
       "\n",
       ">      CounterNetModelConfigs (enc_sizes:List[int], dec_sizes:List[int],\n",
       ">                              exp_sizes:List[int], dropout_rate:float=0.3)\n",
       "\n",
       "Configurator of `CounterNetModel`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| enc_sizes | List[int] |  | Encoder sizes. |\n",
       "| dec_sizes | List[int] |  | Predictor sizes. |\n",
       "| exp_sizes | List[int] |  | CF generator sizes. |\n",
       "| dropout_rate | float | 0.3 | Dropout rate. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc_parser(CounterNetModelConfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/nets.py#L91){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CounterNetModel.__init__\n",
       "\n",
       ">      CounterNetModel.__init__\n",
       ">                                (m_config:Union[Dict,__main__.CounterNetModelCo\n",
       ">                                nfigs], name:str=None)\n",
       "\n",
       "CounterNet model architecture.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| m_config | Dict \\| CounterNetModelConfigs |  | Model configs which contain configs in `CounterNetModelConfigs`. |\n",
       "| name | str | None | Name of the module. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/nets.py#L91){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CounterNetModel.__init__\n",
       "\n",
       ">      CounterNetModel.__init__\n",
       ">                                (m_config:Union[Dict,__main__.CounterNetModelCo\n",
       ">                                nfigs], name:str=None)\n",
       "\n",
       "CounterNet model architecture.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| m_config | Dict \\| CounterNetModelConfigs |  | Model configs which contain configs in `CounterNetModelConfigs`. |\n",
       "| name | str | None | Name of the module. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(CounterNetModel.__init__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CounterNet Training Module\n",
    "\n",
    "Define the `CounterNetTrainingModule` for training `CounterNetModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def partition_trainable_params(params: hk.Params, trainable_name: str):\n",
    "    trainable_params, non_trainable_params = hk.data_structures.partition(\n",
    "        lambda m, n, p: trainable_name in m, params\n",
    "    )\n",
    "    return trainable_params, non_trainable_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def project_immutable_features(x, cf: jnp.DeviceArray, imutable_idx_list: List[int]):\n",
    "    cf = cf.at[:, imutable_idx_list].set(x[:, imutable_idx_list])\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CounterNetTrainingModuleConfigs(BaseParser):\n",
    "    lr: float = 0.003\n",
    "    lambda_1: float = 1.0\n",
    "    lambda_2: float = 0.2\n",
    "    lambda_3: float = 0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CounterNetTrainingModule(BaseTrainingModule):\n",
    "    _data_module: TabularDataModule\n",
    "\n",
    "    def __init__(self, m_configs: Dict[str, Any]):\n",
    "        self.save_hyperparameters(m_configs)\n",
    "        self.net = make_model(m_configs, CounterNetModel)\n",
    "        self.configs = validate_configs(m_configs, CounterNetTrainingModuleConfigs)\n",
    "        # self.configs = CounterNetTrainingModuleConfigs(**m_configs)\n",
    "        self.opt_1 = optax.adam(learning_rate=self.configs.lr)\n",
    "        self.opt_2 = optax.adam(learning_rate=self.configs.lr)\n",
    "\n",
    "    def init_net_opt(self, data_module: TabularDataModule, key):\n",
    "        # hook data_module\n",
    "        self._data_module = data_module\n",
    "        X, _ = data_module.train_dataset[:]\n",
    "\n",
    "        # manually init multiple opts\n",
    "        params, opt_1_state = init_net_opt(\n",
    "            self.net, self.opt_1, X=X[:100], key=key\n",
    "        )\n",
    "        trainable_params, _ = partition_trainable_params(\n",
    "            params, trainable_name=\"counter_net_model/Explainer\"\n",
    "        )\n",
    "        opt_2_state = self.opt_2.init(trainable_params)\n",
    "        return params, (opt_1_state, opt_2_state)\n",
    "\n",
    "    @partial(jax.jit, static_argnames=[\"self\", \"is_training\"])\n",
    "    def forward(self, params, rng_key, x, is_training: bool = True):\n",
    "        # first forward to get y_pred and normalized cf\n",
    "        y_pred, cf = self.net.apply(params, rng_key, x, is_training=is_training)\n",
    "        cf = self._data_module.apply_constraints(x, cf, hard=not is_training)\n",
    "\n",
    "        # second forward to calulate cf_y\n",
    "        cf_y, _ = self.net.apply(params, rng_key, cf, is_training=is_training)\n",
    "        return y_pred, cf, cf_y\n",
    "\n",
    "    def predict(self, params, rng_key, x):\n",
    "        y_pred, _ = self.net.apply(params, rng_key, x, is_training=False)\n",
    "        return y_pred\n",
    "\n",
    "    def generate_cfs(self, X: chex.ArrayBatched, params, rng_key) -> chex.ArrayBatched:\n",
    "        y_pred, cfs = self.net.apply(params, rng_key, X, is_training=False)\n",
    "        # cfs = cfs + X\n",
    "        cfs = self._data_module.apply_constraints(X, cfs, hard=True)\n",
    "        return cfs\n",
    "\n",
    "    def loss_fn_1(self, y_pred, y):\n",
    "        return jnp.mean(vmap(optax.l2_loss)(y_pred, y))\n",
    "\n",
    "    def loss_fn_2(self, cf_y, y_prime):\n",
    "        return jnp.mean(vmap(optax.l2_loss)(cf_y, y_prime))\n",
    "\n",
    "    def loss_fn_3(self, x, cf):\n",
    "        return jnp.mean(vmap(optax.l2_loss)(x, cf))\n",
    "\n",
    "    def pred_loss_fn(self, params, rng_key, batch, is_training: bool = True):\n",
    "        x, y = batch\n",
    "        y_pred, cf = self.net.apply(params, rng_key, x, is_training=is_training)\n",
    "        return self.configs.lambda_1 * self.loss_fn_1(y_pred, y)\n",
    "\n",
    "    def exp_loss_fn(\n",
    "        self,\n",
    "        trainable_params,\n",
    "        non_trainable_params,\n",
    "        rng_key,\n",
    "        batch,\n",
    "        is_training: bool = True,\n",
    "    ):\n",
    "        # merge trainable and non_trainable params\n",
    "        params = hk.data_structures.merge(trainable_params, non_trainable_params)\n",
    "        x, y = batch\n",
    "        y_pred, cf, cf_y = self.forward(params, rng_key, x, is_training=is_training)\n",
    "        y_prime = 1 - jnp.round(y_pred)\n",
    "        loss_2, loss_3 = self.loss_fn_2(cf_y, y_prime), self.loss_fn_3(x, cf)\n",
    "        return self.configs.lambda_2 * loss_2 + self.configs.lambda_3 * loss_3\n",
    "\n",
    "    def _predictor_step(self, params, opt_state, rng_key, batch):\n",
    "        grads = jax.grad(self.pred_loss_fn)(params, rng_key, batch)\n",
    "        upt_params, opt_state = grad_update(grads, params, opt_state, self.opt_1)\n",
    "        return upt_params, opt_state\n",
    "\n",
    "    def _explainer_step(self, params, opt_state, rng_key, batch):\n",
    "        trainable_params, non_trainable_params = partition_trainable_params(\n",
    "            params, trainable_name=\"counter_net_model/Explainer\"\n",
    "        )\n",
    "        grads = jax.grad(self.exp_loss_fn)(\n",
    "            trainable_params, non_trainable_params, rng_key, batch\n",
    "        )\n",
    "        upt_trainable_params, opt_state = grad_update(\n",
    "            grads, trainable_params, opt_state, self.opt_2\n",
    "        )\n",
    "        upt_params = hk.data_structures.merge(\n",
    "            upt_trainable_params, non_trainable_params\n",
    "        )\n",
    "        return upt_params, opt_state\n",
    "\n",
    "    @partial(jax.jit, static_argnames=[\"self\"])\n",
    "    def _training_step(\n",
    "        self,\n",
    "        params: hk.Params,\n",
    "        opts_state: Tuple[optax.GradientTransformation, optax.GradientTransformation],\n",
    "        rng_key: random.PRNGKey,\n",
    "        batch: Tuple[jnp.array, jnp.array],\n",
    "    ):\n",
    "        opt_1_state, opt_2_state = opts_state\n",
    "        params, opt_1_state = self._predictor_step(params, opt_1_state, rng_key, batch)\n",
    "        upt_params, opt_2_state = self._explainer_step(\n",
    "            params, opt_2_state, rng_key, batch\n",
    "        )\n",
    "        return upt_params, (opt_1_state, opt_2_state)\n",
    "\n",
    "    def _training_step_logs(self, params, rng_key, batch):\n",
    "        x, y = batch\n",
    "        y_pred, cf, cf_y = self.forward(params, rng_key, x, is_training=False)\n",
    "        y_prime = 1 - jnp.round(y_pred)\n",
    "\n",
    "        loss_1, loss_2, loss_3 = (\n",
    "            self.loss_fn_1(y_pred, y),\n",
    "            self.loss_fn_2(cf_y, y_prime),\n",
    "            self.loss_fn_3(x, cf),\n",
    "        )\n",
    "        logs = {\n",
    "            \"train/train_loss_1\": loss_1.item(),\n",
    "            \"train/train_loss_2\": loss_2.item(),\n",
    "            \"train/train_loss_3\": loss_3.item(),\n",
    "        }\n",
    "        return logs\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        params: hk.Params,\n",
    "        opts_state: Tuple[optax.OptState, optax.OptState],\n",
    "        rng_key: random.PRNGKey,\n",
    "        batch: Tuple[jnp.array, jnp.array],\n",
    "    ) -> Tuple[hk.Params, Tuple[optax.OptState, optax.OptState]]:\n",
    "        upt_params, (opt_1_state, opt_2_state) = self._training_step(\n",
    "            params, opts_state, rng_key, batch\n",
    "        )\n",
    "\n",
    "        logs = self._training_step_logs(upt_params, rng_key, batch)\n",
    "        self.log_dict(logs)\n",
    "        return upt_params, (opt_1_state, opt_2_state)\n",
    "\n",
    "    def validation_step(self, params, rng_key, batch):\n",
    "        x, y = batch\n",
    "        y_pred, cf, cf_y = self.forward(params, rng_key, x, is_training=False)\n",
    "        y_prime = 1 - jnp.round(y_pred)\n",
    "\n",
    "        loss_1, loss_2, loss_3 = (\n",
    "            self.loss_fn_1(y_pred, y),\n",
    "            self.loss_fn_2(cf_y, y_prime),\n",
    "            self.loss_fn_3(x, cf),\n",
    "        )\n",
    "        loss_1, loss_2, loss_3 = map(np.asarray, (loss_1, loss_2, loss_3))\n",
    "        logs = {\n",
    "            \"val/accuracy\": accuracy(y, y_pred),\n",
    "            \"val/validity\": accuracy(cf_y, y_prime),\n",
    "            \"val/proximity\": proximity(x, cf),\n",
    "            \"val/val_loss_1\": loss_1,\n",
    "            \"val/val_loss_2\": loss_2,\n",
    "            \"val/val_loss_3\": loss_3,\n",
    "            \"val/val_loss\": loss_1 + loss_2 + loss_3,\n",
    "        }\n",
    "        self.log_dict(logs)\n",
    "        return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CounterNet Explanation Module\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CounterNet architecture](images/CounterNet-architecture.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CounterNet` consists of three objectives:\n",
    "\n",
    "1. **predictive accuracy**: the predictor network should output accurate predictions $\\hat{y}_x$; \n",
    "2. **counterfactual validity**: CF examples $x'$ produced by the CF generator network should be valid (e.g. $\\hat{y}_{x} + \\hat{y}_{x'}=1$);\n",
    "3. **minimizing cost of change**: minimal modifications should be required to change input instance $x$ to CF example $x'$.\n",
    "\n",
    "The objective function of `CounterNet`:\n",
    "\n",
    "$$\n",
    "\\operatorname*{argmin}_{\\mathbf{\\theta}} \\frac{1}{N}\\sum\\nolimits_{i=1}^{N} \n",
    "    \\bigg[ \n",
    "    \\lambda_1 \\cdot \\! \\underbrace{\\left(y_i- \\hat{y}_{x_i}\\right)^2}_{\\text{Prediction Loss}\\ (\\mathcal{L}_1)} + \n",
    "    \\;\\lambda_2 \\cdot \\;\\; \\underbrace{\\left(\\hat{y}_{x_i}- \\left(1 - \\hat{y}_{x_i'}\\right)\\right)^2}_{\\text{Validity Loss}\\ (\\mathcal{L}_2)} \\,+ \n",
    "    \\;\\lambda_3 \\cdot \\!\\! \\underbrace{\\left(x_i- x'_i\\right)^2}_{\\text{Cost of change Loss}\\ (\\mathcal{L}_3)}\n",
    "    \\bigg]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CounterNet` applies two-stage gradient updates to `CounterNetModel` \n",
    "for each `training_step` (see `CounterNetTrainingModule`).\n",
    "\n",
    "1. The first gradient update optimizes for predictive accuracy: \n",
    "$\\theta^{(1)} = \\theta^{(0)} - \\nabla_{\\theta^{(0)}} (\\lambda_1 \\cdot \\mathcal{L}_1)$.\n",
    "2. The second gradient update optimizes for generating CF explanation:\n",
    "$\\theta^{(2)}_g = \\theta^{(1)}_g - \\nabla_{\\theta^{(1)}_g} (\\mathcal \\lambda_2 \\cdot \\mathcal{L}_2 + \\lambda_3 \\cdot \\mathcal{L}_3)$\n",
    "\n",
    "The design choice of this optimizing procedure is made due to *improved convergence of the model*,\n",
    "and *improved adversarial robustness of the predictor network*. \n",
    "The [CounterNet paper](https://arxiv.org/abs/2109.07557) elaborates the design choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "class CounterNetConfigs(CounterNetTrainingModuleConfigs, CounterNetModelConfigs):\n",
    "    \"\"\"Configurator of `CounterNet`.\"\"\"\n",
    "\n",
    "    enc_sizes: List[int] = Field(\n",
    "        [50,10], description=\"Sequence of layer sizes for encoder network.\"\n",
    "    )\n",
    "    dec_sizes: List[int] = Field(\n",
    "        [10], description=\"Sequence of layer sizes for predictor.\"\n",
    "    ) \n",
    "    exp_sizes: List[int] = Field(\n",
    "        [50, 50], description=\"Sequence of layer sizes for CF generator.\"\n",
    "    )\n",
    "    \n",
    "    dropout_rate: float = Field(\n",
    "        0.3, description=\"Dropout rate.\"\n",
    "    )\n",
    "    lr: float = Field(\n",
    "        0.003, description=\"Learning rate for training `CounterNet`.\"\n",
    "    ) \n",
    "    lambda_1: float = Field(\n",
    "        1.0, description=\" $\\lambda_1$ for balancing the prediction loss $\\mathcal{L}_1$.\"\n",
    "    ) \n",
    "    lambda_2: float = Field(\n",
    "        0.2, description=\" $\\lambda_2$ for balancing the prediction loss $\\mathcal{L}_2$.\"\n",
    "    ) \n",
    "    lambda_3: float = Field(\n",
    "        0.1, description=\" $\\lambda_3$ for balancing the prediction loss $\\mathcal{L}_3$.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/methods/counternet.py#L260){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CounterNetConfigs\n",
       "\n",
       ">      CounterNetConfigs (enc_sizes:List[int]=[50, 10],\n",
       ">                         dec_sizes:List[int]=[10], exp_sizes:List[int]=[50,\n",
       ">                         50], dropout_rate:float=0.3, lr:float=0.003,\n",
       ">                         lambda_1:float=1.0, lambda_2:float=0.2,\n",
       ">                         lambda_3:float=0.1)\n",
       "\n",
       "Configurator of `CounterNet`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| enc_sizes | List[int] | [50, 10] | Sequence of layer sizes for encoder network. |\n",
       "| dec_sizes | List[int] | [10] | Sequence of layer sizes for predictor. |\n",
       "| exp_sizes | List[int] | [50, 50] | Sequence of layer sizes for CF generator. |\n",
       "| dropout_rate | float | 0.3 | Dropout rate. |\n",
       "| lr | float | 0.003 | Learning rate for training `CounterNet`. |\n",
       "| lambda_1 | float | 1.0 |  $\\lambda_1$ for balancing the prediction loss $\\mathcal{L}_1$. |\n",
       "| lambda_2 | float | 0.2 |  $\\lambda_2$ for balancing the prediction loss $\\mathcal{L}_2$. |\n",
       "| lambda_3 | float | 0.1 |  $\\lambda_3$ for balancing the prediction loss $\\mathcal{L}_3$. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/cfnet/methods/counternet.py#L260){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### CounterNetConfigs\n",
       "\n",
       ">      CounterNetConfigs (enc_sizes:List[int]=[50, 10],\n",
       ">                         dec_sizes:List[int]=[10], exp_sizes:List[int]=[50,\n",
       ">                         50], dropout_rate:float=0.3, lr:float=0.003,\n",
       ">                         lambda_1:float=1.0, lambda_2:float=0.2,\n",
       ">                         lambda_3:float=0.1)\n",
       "\n",
       "Configurator of `CounterNet`.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| enc_sizes | List[int] | [50, 10] | Sequence of layer sizes for encoder network. |\n",
       "| dec_sizes | List[int] | [10] | Sequence of layer sizes for predictor. |\n",
       "| exp_sizes | List[int] | [50, 50] | Sequence of layer sizes for CF generator. |\n",
       "| dropout_rate | float | 0.3 | Dropout rate. |\n",
       "| lr | float | 0.003 | Learning rate for training `CounterNet`. |\n",
       "| lambda_1 | float | 1.0 |  $\\lambda_1$ for balancing the prediction loss $\\mathcal{L}_1$. |\n",
       "| lambda_2 | float | 0.2 |  $\\lambda_2$ for balancing the prediction loss $\\mathcal{L}_2$. |\n",
       "| lambda_3 | float | 0.1 |  $\\lambda_3$ for balancing the prediction loss $\\mathcal{L}_3$. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc_parser(CounterNetConfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CounterNet(BaseCFModule, BaseParametricCFModule, BasePredFnCFModule):\n",
    "    \"\"\"API for CounterNet Explanation Module.\"\"\"\n",
    "    params: hk.Params = None\n",
    "    module: CounterNetTrainingModule\n",
    "    name: str = 'CounterNet'\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        m_configs: dict | CounterNetConfigs = None # configurator of hyperparamters; see `CounterNetConfigs`\n",
    "    ):\n",
    "        if m_configs is None:\n",
    "            m_configs = CounterNetConfigs()\n",
    "        self.module = CounterNetTrainingModule(m_configs)\n",
    "\n",
    "    def _is_module_trained(self):\n",
    "        return not (self.params is None)\n",
    "    \n",
    "    def train(\n",
    "        self, \n",
    "        datamodule: TabularDataModule, # data module\n",
    "        t_configs: TrainingConfigs | dict = None # training configs\n",
    "    ):\n",
    "        _default_t_configs = dict(\n",
    "            n_epochs=100, batch_size=128\n",
    "        )\n",
    "        if t_configs is None: t_configs = _default_t_configs\n",
    "        params, _ = train_model(self.module, datamodule, t_configs)\n",
    "        self.params = params\n",
    "\n",
    "    def generate_cfs(self, X: jnp.ndarray, pred_fn = None) -> jnp.ndarray:\n",
    "        return self.module.generate_cfs(X, self.params, rng_key=jax.random.PRNGKey(0))\n",
    "    \n",
    "    def pred_fn(self, X: jnp.DeviceArray):\n",
    "        rng_key = jax.random.PRNGKey(0)\n",
    "        y_pred = self.module.predict(self.params, rng_key, X)\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic usage of `CounterNet`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dm = load_data(\"adult\", data_configs=dict(sample_frac=0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `CounterNet`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counternet = CounterNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(counternet, BaseParametricCFModule)\n",
    "assert isinstance(counternet, BaseCFModule)\n",
    "assert isinstance(counternet, BasePredFnCFModule)\n",
    "assert hasattr(counternet, 'pred_fn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/code/cfnet/cfnet/_ckpt_manager.py:48: UserWarning: `monitor_metrics` is not specified in `CheckpointManager`. No checkpoints will be stored.\n",
      "  \"`monitor_metrics` is not specified in `CheckpointManager`. No checkpoints will be stored.\"\n",
      "Epoch 0: 100%|██████████| 191/191 [00:09<00:00, 20.36batch/s, train/train_loss_1=0.0595, train/train_loss_2=0.0545, train/train_loss_3=0.1]    \n"
     ]
    }
   ],
   "source": [
    "#| output: false\n",
    "t_configs = dict(n_epochs=1, batch_size=128)\n",
    "counternet.train(dm, t_configs=t_configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dm.test_dataset[:]\n",
    "y_pred = counternet.pred_fn(X)\n",
    "assert y_pred.shape == (len(y), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate CF explanations for given `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = dm.test_dataset[:]\n",
    "cfs = counternet.generate_cfs(X)\n",
    "assert X.shape == cfs.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev2",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
