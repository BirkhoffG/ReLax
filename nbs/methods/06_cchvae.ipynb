{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCHVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods.cchvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from nbdev import show_doc\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from relax.import_essentials import *\n",
    "from relax.methods.base import BaseCFModule, BaseParametricCFModule\n",
    "from relax.utils import *\n",
    "from relax.module import MLP, BaseTrainingModule\n",
    "from relax.data import *\n",
    "from relax.trainer import train_model, TrainingConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class Encoder(hk.Module):\n",
    "    def __init__(self, sizes):\n",
    "        super().__init__()\n",
    "        self.encoder = MLP(sizes[:-1], name=\"Encoder\")\n",
    "        self.encoded_size = sizes[-1]\n",
    "    \n",
    "    def __call__(self, x: Array, is_training: bool):\n",
    "        mu_enc = hk.Sequential([\n",
    "            self.encoder, hk.Linear(self.encoded_size, name='mu_z')\n",
    "        ])(x)\n",
    "        logvar_enc = hk.Sequential([\n",
    "            self.encoder, hk.Linear(self.encoded_size, name='logvar_z')\n",
    "        ])(x)\n",
    "        return mu_enc, logvar_enc\n",
    "\n",
    "class Decoder(hk.Module):\n",
    "    def __init__(self, sizes, input_size):\n",
    "        super().__init__()\n",
    "        self.decoder = MLP(sizes, name=\"Decoder\")\n",
    "        self.input_size = input_size\n",
    "    \n",
    "    def __call__(self, z: Array, is_training: bool):\n",
    "        mu_dec = self.decoder(z)\n",
    "        # TODO: use batchnorm\n",
    "        # mu_dec = hk.BatchNorm(True, True, 0.9)(mu_dec, is_training)\n",
    "        mu_dec = hk.Linear(self.input_size, name='mu_x')(mu_dec)\n",
    "        \n",
    "        logvar_dec = self.decoder(z)\n",
    "        # TODO: use batchnorm\n",
    "        # logvar_dec = hk.BatchNorm(True, True, 0.9)(logvar_dec, is_training)\n",
    "        logvar_dec = hk.Linear(self.input_size, name='logvar_x')(logvar_dec)\n",
    "\n",
    "        return mu_dec, logvar_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class CHVAEConfigs(BaseParser):\n",
    "    enc_sizes: List[int] = [20, 16, 14, 12, 5]\n",
    "    dec_sizes: List[int] = [12, 14, 16, 20]\n",
    "    lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "class CHVAE(BaseTrainingModule):\n",
    "    def __init__(self, m_config: Dict):\n",
    "        self.save_hyperparameters(m_config)\n",
    "        self.m_config = validate_configs(m_config, CHVAEConfigs)\n",
    "        self.opt = optax.adam(self.m_config.lr)\n",
    "\n",
    "    def init_net_opt(self, dm, key):\n",
    "        X, _ = dm.train_dataset[:128]\n",
    "        encoded_size = self.m_config.enc_sizes[-1]\n",
    "        Z = jnp.ones((X.shape[0], encoded_size))\n",
    "\n",
    "        self.encoder = make_hk_module(\n",
    "            Encoder, sizes=self.m_config.enc_sizes, \n",
    "        )\n",
    "        self.decoder = make_hk_module(\n",
    "            Decoder, sizes=self.m_config.dec_sizes,\n",
    "            input_size=X.shape[-1]\n",
    "        )\n",
    "\n",
    "        enc_params = self.encoder.init(key, X, is_training=True)\n",
    "        dec_params = self.decoder.init(key, Z, is_training=True)\n",
    "        opt_state = self.opt.init((enc_params, dec_params))\n",
    "        return (enc_params, dec_params), opt_state\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def encode(self, enc_params, rng_key, x):\n",
    "        mu_z, logvar_z = self.encoder.apply(enc_params, rng_key, x, is_training=True)\n",
    "        return mu_z, logvar_z\n",
    "        \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def __reparameterize(self, rng_key, mu, logvar):\n",
    "        std = jnp.exp(0.5 * logvar)\n",
    "        eps = jax.random.normal(rng_key, std.shape)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def decode(self, dec_params, rng_key, z):\n",
    "        mu_x, logvar_x = self.decoder.apply(dec_params, rng_key, z, is_training=True)\n",
    "        return mu_x, logvar_x\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def forward(self, params, rng_key, x):\n",
    "        enc_params, dec_params = params\n",
    "        keys = jax.random.split(rng_key, 3)\n",
    "        mu_z, logvar_z = self.encode(enc_params, keys[0], x)\n",
    "        z_rep = self.__reparameterize(keys[1], mu_z, logvar_z)\n",
    "        mu_x, logvar_x = self.decode(dec_params, keys[2], z_rep)\n",
    "        return mu_x, logvar_x, mu_z, logvar_z, z_rep\n",
    "    \n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def loss(self, params, rng_key, x):\n",
    "        mu_x, logvar_x, mu_z, logvar_z, z_rep = self.forward(params, rng_key, x)\n",
    "        recon_loss = jnp.mean(optax.l2_loss(mu_x, x))\n",
    "        # kl_loss = -0.5 * jnp.sum(1 + logvar_z - mu_z**2 - jnp.exp(logvar_z))\n",
    "        kl_loss = -0.5 * jnp.sum(1 + logvar_z - jnp.power(mu_z, 2) - jnp.exp(logvar_z))\n",
    "        loss = recon_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    @partial(jax.jit, static_argnums=(0,))\n",
    "    def _training_step(\n",
    "        self, \n",
    "        params: Tuple[hk.Params, hk.Params],\n",
    "        opt_state: optax.OptState, \n",
    "        rng_key: random.PRNGKey, \n",
    "        batch: Tuple[jnp.array, jnp.array]\n",
    "    ) -> Tuple[hk.Params, optax.OptState]:\n",
    "        loss, grads = jax.value_and_grad(self.loss)(\n",
    "            params, rng_key, batch[0])\n",
    "        update_params, opt_state = grad_update(\n",
    "            grads, params, opt_state, self.opt)\n",
    "        return update_params, opt_state, loss\n",
    "\n",
    "    def training_step(\n",
    "        self,\n",
    "        params: Tuple[hk.Params, hk.Params],\n",
    "        opt_state: optax.OptState,\n",
    "        rng_key: random.PRNGKey,\n",
    "        batch: Tuple[jnp.array, jnp.array]\n",
    "    ) -> Tuple[hk.Params, optax.OptState]:\n",
    "        params, opt_state, loss = self._training_step(params, opt_state, rng_key, batch)\n",
    "        self.log_dict({'train/loss': loss.item()})\n",
    "        return params, opt_state\n",
    "    \n",
    "    def validation_step(\n",
    "        self,\n",
    "        params: Tuple[hk.Params, hk.Params],\n",
    "        rng_key: random.PRNGKey,\n",
    "        batch: Tuple[jnp.array, jnp.array],\n",
    "    ) -> Tuple[hk.Params, optax.OptState]:\n",
    "        loss = self.loss(params, rng_key, batch[0])\n",
    "        self.log_dict({'val/loss': loss.item()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _hyper_sphere_coordindates(\n",
    "    rng_key: jrand.PRNGKey, # Random number generator key\n",
    "    x: Array, # Input instance with only continuous features. Shape: (1, n_features)\n",
    "    n_samples: int,\n",
    "    high: float, # Upper bound\n",
    "    low: float, # Lower bound\n",
    "    p_norm: int = 2 # Norm\n",
    "):\n",
    "    key_1, key_2 = jrand.split(rng_key)\n",
    "    delta = jrand.normal(key_1, shape=(n_samples, x.shape[-1]))\n",
    "    dist = jrand.normal(key_2, shape=(n_samples,)) * (high - low) + low\n",
    "    norm_p = jnp.linalg.norm(delta, ord=p_norm, axis=1)\n",
    "    d_norm = jnp.divide(dist, norm_p).reshape(-1, 1)  # rescale/normalize factor\n",
    "    delta = jnp.multiply(delta, d_norm)\n",
    "    candidates = x + delta\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@auto_reshaping('x')\n",
    "def _cchvae_generate(\n",
    "    x: Array,\n",
    "    rng_key: random.PRNGKey,\n",
    "    pred_fn: Callable,\n",
    "    max_steps: int,\n",
    "    n_search_samples: int,\n",
    "    step_size: float,\n",
    "    cchvae_module: CHVAE,\n",
    "    cchvae_params: Tuple[hk.Params, hk.Params],\n",
    "    apply_fn: Callable,\n",
    "):\n",
    "    @jit\n",
    "    def cond_fn(state):\n",
    "        count, cf, _ = state\n",
    "        return jnp.logical_and(count < max_steps, jnp.array_equal(x, cf))\n",
    "    \n",
    "    @jit\n",
    "    def body_fn(state):\n",
    "        count, candidate_cf, rng = state\n",
    "        rng_key, subkey_1, subkey_2 = jrand.split(rng, num=3)\n",
    "        low, high = step_size * count, step_size * (count + 1)\n",
    "        # STEP 1 -- SAMPLE POINTS on hyper sphere around instance\n",
    "        latent_neighbors = _hyper_sphere_coordindates(\n",
    "            subkey_1, z_rep, n_search_samples, high=high, low=low, p_norm=1\n",
    "        )\n",
    "        x_ce, _ = cchvae_module.decode(cchvae_params[1], subkey_2, latent_neighbors)\n",
    "        x_ce = apply_fn(x, x_ce.reshape(1, -1), hard=True)\n",
    "        \n",
    "        # STEP 2 -- COMPUTE l1 norms\n",
    "        distances = jnp.abs(x_ce - x).sum(axis=1)\n",
    "\n",
    "        # STEP 3 -- SELECT POINT with MINIMUM l1 norm\n",
    "        y_candidates = pred_fn(x_ce).round().reshape(-1)\n",
    "        indices = jnp.where(y_candidates != y_pred, 1, 0).astype(bool)\n",
    "        distances = jnp.where(indices, distances, jnp.inf)\n",
    "        \n",
    "        candidate_cf = lax.cond(\n",
    "            jnp.any(indices),\n",
    "            lambda _: x_ce[jnp.argmin(distances)].reshape(1, -1),\n",
    "            lambda _: candidate_cf,\n",
    "            None\n",
    "        )\n",
    "\n",
    "        count += 1\n",
    "        return count, candidate_cf, rng_key\n",
    "    \n",
    "    y_pred = pred_fn(x).round().reshape(-1)\n",
    "    z, _ = cchvae_module.encode(cchvae_params[0], rng_key, x)\n",
    "    # z_rep = jnp.repeat(z.reshape(1, -1), n_search_samples, axis=0)\n",
    "    z_rep = z.reshape(1, -1)\n",
    "    rng_key, _ = jrand.split(rng_key)\n",
    "    state = (0, x, rng_key) # (count, candidate_cf, rng_key)\n",
    "    count, candidate_cf, rng_key = jax.lax.while_loop(cond_fn, body_fn, state)\n",
    "    # while cond_fn(state):\n",
    "    #     count, candidate_cf, rng_key = body_fn(state)\n",
    "    # print(count)\n",
    "    return candidate_cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CCHVAEConfigs(BaseParser):\n",
    "    enc_sizes: List[int] = Field(\n",
    "        [20, 16, 14, 12], description=\"Encoder hidden sizes\"\n",
    "    ) \n",
    "    dec_sizes: List[int] = Field(\n",
    "        [12, 14, 16, 20], description=\"Decoder hidden sizes\"\n",
    "    )\n",
    "    encoded_size: int = Field(5, description=\"Encoded size\")\n",
    "    lr: float = Field(0.001, description=\"Learning rate\")\n",
    "    max_steps: int = Field(1000, description=\"Max steps\")\n",
    "    n_search_samples: int = Field(300, description=\"Number of generated candidate counterfactuals.\")\n",
    "    step_size: float = Field(0.1, description=\"Step size\")\n",
    "    seed: int = Field(0, description=\"Seed for random number generator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class CCHVAE(BaseCFModule, BaseParametricCFModule):\n",
    "    params: Tuple[hk.Params, hk.Params] = None\n",
    "    module: CHVAE\n",
    "    name: str = 'C-CHVAE'\n",
    "\n",
    "    def __init__(self, configs: Dict | CCHVAEConfigs = None):\n",
    "        if configs is None:\n",
    "            configs = CCHVAEConfigs()\n",
    "        self.configs = validate_configs(configs, CCHVAEConfigs)\n",
    "        self.module = CHVAE(self.configs.dict())\n",
    "        self.rng_key = random.PRNGKey(self.configs.seed)\n",
    "\n",
    "    def _is_module_trained(self) -> bool:\n",
    "        return not (self.params is None)\n",
    "    \n",
    "    def train(\n",
    "        self, \n",
    "        datamodule: TabularDataModule, # data module\n",
    "        t_configs: TrainingConfigs | dict = None, # training configs\n",
    "        *args, **kwargs\n",
    "    ):\n",
    "        _default_t_configs = dict(\n",
    "            n_epochs=10, batch_size=128\n",
    "        )\n",
    "        if t_configs is None: t_configs = _default_t_configs\n",
    "        params, _ = train_model(self.module, datamodule, t_configs)\n",
    "        self.params = params\n",
    "\n",
    "    def generate_cf(self, x: Array, pred_fn: Callable = None) -> jnp.ndarray:\n",
    "        _cchvae_generate_fn_partial = partial(\n",
    "            _cchvae_generate,\n",
    "            pred_fn=pred_fn,\n",
    "            max_steps=self.configs.max_steps,\n",
    "            n_search_samples=self.configs.n_search_samples,\n",
    "            step_size=self.configs.step_size,\n",
    "            cchvae_module=self.module,\n",
    "            cchvae_params=self.params,\n",
    "            apply_fn=self.data_module.apply_constraints,\n",
    "        )\n",
    "        return _cchvae_generate_fn_partial(x, self.rng_key)\n",
    "    \n",
    "    def generate_cfs(self, X: Array, pred_fn: Callable = None) -> jnp.ndarray:\n",
    "        _cchvae_generate_fn_partial = partial(\n",
    "            _cchvae_generate,\n",
    "            pred_fn=pred_fn,\n",
    "            max_steps=self.configs.max_steps,\n",
    "            n_search_samples=self.configs.n_search_samples,\n",
    "            step_size=self.configs.step_size,\n",
    "            cchvae_module=self.module,\n",
    "            cchvae_params=self.params,\n",
    "            apply_fn=self.data_module.apply_constraints,\n",
    "        )\n",
    "        rngs = lax.broadcast(self.rng_key, (X.shape[0], ))\n",
    "        return jax.vmap(_cchvae_generate_fn_partial)(X, rngs)\n",
    "        # for i in tqdm(range(X.shape[0])):\n",
    "        #     rng = random.PRNGKey(i)\n",
    "        #     cf = _cchvae_generate_fn_partial(X[i], rng)\n",
    "        #     if i == 0:\n",
    "        #         cfs = cf\n",
    "        #     else:\n",
    "        #         cfs = jnp.concatenate([cfs, cf], axis=0)\n",
    "        # return cfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.module import PredictiveTrainingModule\n",
    "from relax.evaluate import generate_cf_explanations, benchmark_cfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = load_data('adult', data_configs=dict(sample_frac=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/relax/_ckpt_manager.py:47: UserWarning: `monitor_metrics` is not specified in `CheckpointManager`. No checkpoints will be stored.\n",
      "  warnings.warn(\n",
      "Epoch 4: 100%|██████████| 10/10 [00:00<00:00, 371.32batch/s, train/train_loss_1=0.072]\n"
     ]
    }
   ],
   "source": [
    "configs = dict(sizes=[50, 10, 50], lr=0.03)\n",
    "t_config = dict(n_epochs=5, batch_size=256)\n",
    "\n",
    "training_module = PredictiveTrainingModule(configs)\n",
    "params, opt_state = train_model(\n",
    "    training_module, dm, t_config\n",
    ")\n",
    "# predict function\n",
    "# pred_fn = lambda x: training_module.forward(params, x, is_training=False)\n",
    "pred_fn = lambda x, params, key: training_module.forward(\n",
    "    params, key, x, is_training=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/haiku/_src/base.py:515: UserWarning: Explicitly requested dtype float64 requested in zeros is not available, and will be truncated to dtype float32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  param = init(shape, dtype)\n",
      "/Users/chuck/opt/anaconda3/envs/relax/lib/python3.8/site-packages/relax/_ckpt_manager.py:47: UserWarning: `monitor_metrics` is not specified in `CheckpointManager`. No checkpoints will be stored.\n",
      "  warnings.warn(\n",
      "Epoch 9: 100%|██████████| 20/20 [00:00<00:00, 497.66batch/s, train/loss=1.62]\n"
     ]
    }
   ],
   "source": [
    "cchvae_test = CCHVAE({'max_steps': 10, 'lr': 0.05})\n",
    "cchvae_test.train(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_exp = generate_cf_explanations(\n",
    "    cchvae_test, dm, pred_fn, pred_fn_args=dict(\n",
    "        params=params, key=random.PRNGKey(0)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>validity</th>\n",
       "      <th>proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <th>C-CHVAE</th>\n",
       "      <td>0.823855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.995618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc  validity  proximity\n",
       "adult C-CHVAE  0.823855       1.0   5.995618"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_cfs([cf_exp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
