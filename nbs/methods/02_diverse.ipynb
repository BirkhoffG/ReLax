{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diverse CF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp methods.diverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from relax.import_essentials import *\n",
    "from relax.methods.base import BaseCFModule\n",
    "from relax.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def hinge_loss(input: jax.Array, target: jax.Array):\n",
    "    \"\"\"\n",
    "    reference:\n",
    "    - https://github.com/interpretml/DiCE/blob/a772c8d4fcd88d1cab7f2e02b0bcc045dc0e2eab/dice_ml/explainer_interfaces/dice_pytorch.py#L196-L202\n",
    "    - https://en.wikipedia.org/wiki/Hinge_loss\n",
    "    \"\"\"\n",
    "    input = jnp.log((jnp.abs(input - 1e-6) / (1 - jnp.abs(input - 1e-6))))\n",
    "    all_ones = jnp.ones_like(target)\n",
    "    target = 2 * target - all_ones\n",
    "    loss = all_ones - target * input\n",
    "    loss = jax.nn.relu(loss)\n",
    "    return jnp.linalg.norm(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def l1_mean(X, cfs):\n",
    "    x_mean = jnp.mean(jnp.abs(X))\n",
    "    l1_loss = jnp.mean(jnp.abs(X - cfs))\n",
    "    return l1_loss / x_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def dpp_style(cf: jax.Array, n_cfs: int):\n",
    "    det_entries = jnp.ones((n_cfs, n_cfs))\n",
    "    for i in range(n_cfs):\n",
    "        for j in range(n_cfs):\n",
    "            det_entries.at[i, j].set(dist(cf[i], cf[j], ord=1))\n",
    "\n",
    "    det_entries = 1.0 / (1.0 + det_entries)\n",
    "    det_entries += jnp.eye(n_cfs) * 0.0001\n",
    "    return jnp.linalg.det(det_entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "def _compute_regularization_loss(cfs, cat_idx, cat_arrays, n_cfs):\n",
    "    # cat_idx = len(self.model.continous_cols)\n",
    "    regularization_loss = 0.0\n",
    "    for i in range(n_cfs):\n",
    "        for col in cat_arrays:\n",
    "            cat_idx_end = cat_idx + len(col)\n",
    "            regularization_loss += jnp.power(\n",
    "                (jnp.sum(cfs[i][cat_idx:cat_idx_end]) - 1.0), 2\n",
    "            )\n",
    "    return regularization_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| exporti\n",
    "@auto_reshaping('x')\n",
    "def _diverse_cf(\n",
    "    x: jax.Array,  # `x` shape: (k,), where `k` is the number of features\n",
    "    pred_fn: Callable[[jax.Array], jax.Array],  # y = pred_fn(x)\n",
    "    n_cfs: int,\n",
    "    n_steps: int,\n",
    "    lr: float,  # learning rate for each `cf` optimization step\n",
    "    lambda_: float,  #  loss = validity_loss + lambda_params * cost\n",
    "    key: jax.random.PRNGKey,\n",
    "    projection_fn: Callable,\n",
    "    regularization_fn: Callable\n",
    ") -> jax.Array:  # return `cf` shape: (k,)\n",
    "    @jit\n",
    "    def loss_fn_1(cf_y: Array, y_prime: Array):\n",
    "        return optax.l2_loss(cf_y.mean(axis=0, keepdims=True), y_prime).mean()\n",
    "\n",
    "    @jit\n",
    "    def loss_fn_2(x: Array, cf: Array):\n",
    "        return jnp.mean(jnp.abs(cf - x))\n",
    "\n",
    "    @partial(jit, static_argnums=(1,))\n",
    "    def loss_fn_3(cfs: jax.Array, n_cfs: int):\n",
    "        return dpp_style(cfs, n_cfs)\n",
    "\n",
    "    @jit\n",
    "    def loss_fn_4(x: Array, cfs: Array):\n",
    "        # return _compute_regularization_loss(cfs, cat_idx, cat_arrays, n_cfs)\n",
    "        reg_loss = 0.\n",
    "        for i in range(n_cfs):\n",
    "            reg_loss += regularization_fn(x, cfs[i])\n",
    "        return reg_loss\n",
    "\n",
    "    @partial(jit, static_argnums=(2,))\n",
    "    def loss_fn(\n",
    "        cf: jax.Array,  # `cf` shape: (k, n_cfs)\n",
    "        x: jax.Array,  # `x` shape: (k, 1)\n",
    "        pred_fn: Callable[[Array], Array],\n",
    "    ):\n",
    "        y_pred = pred_fn(x)\n",
    "        y_prime = 1.0 - y_pred\n",
    "        cf_y = pred_fn(cf)\n",
    "\n",
    "        loss_1 = loss_fn_1(cf_y, y_prime)\n",
    "        loss_2 = loss_fn_2(x, cf)\n",
    "        loss_3 = loss_fn_3(cf, n_cfs)\n",
    "        loss_4 = loss_fn_4(x, cfs)\n",
    "        return loss_1 + 0.01 * loss_2 + loss_3 + 0.1 * loss_4\n",
    "\n",
    "    @loop_tqdm(n_steps)\n",
    "    def gen_cf_step(\n",
    "        i, cf_opt_state: Tuple[Array, optax.OptState]\n",
    "    ) -> Tuple[Array, optax.OptState]:\n",
    "        cf, opt_state = cf_opt_state\n",
    "        cf_grads = jax.grad(loss_fn)(cf, x, pred_fn)\n",
    "        cf, opt_state = grad_update(cf_grads, cf, opt_state, opt)\n",
    "        return cf, opt_state\n",
    "\n",
    "    key, subkey = jax.random.split(key)\n",
    "    cfs = jax.random.normal(key, shape=(n_cfs, x.shape[-1]))\n",
    "    opt = optax.adam(lr)\n",
    "    opt_state = opt.init(cfs)\n",
    "    cfs, opt_state = lax.fori_loop(0, n_steps, gen_cf_step, (cfs, opt_state))\n",
    "    # for _ in tqdm(range(n_steps)):\n",
    "    #     cfs, opt_state = gen_cf_step(x, cfs, opt_state)\n",
    "    cf = projection_fn(x, cfs[:1, :], hard=True)\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "class DiverseCFConfig(BaseParser):\n",
    "    n_cfs: int = 5\n",
    "    n_steps: int = 1000\n",
    "    lr: float = 0.01\n",
    "    lambda_: float = 0.01  # loss = validity_loss + lambda_params * cost\n",
    "    seed: int = 42\n",
    "\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return hk.PRNGSequence(self.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class DiverseCF(BaseCFModule):\n",
    "    name = \"DiverseCF\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        configs: Union[Dict[str, Any], DiverseCFConfig] = None,\n",
    "    ):\n",
    "        if configs is None:\n",
    "            configs = DiverseCFConfig()\n",
    "        self.configs = validate_configs(configs, DiverseCFConfig)\n",
    "\n",
    "    def generate_cf(\n",
    "        self,\n",
    "        x: jnp.ndarray,  # `x` shape: (k,), where `k` is the number of features\n",
    "        pred_fn: Callable[[jax.Array], jax.Array],\n",
    "    ) -> jax.Array:\n",
    "        return _diverse_cf(\n",
    "            x=x,  # `x` shape: (k,), where `k` is the number of features\n",
    "            pred_fn=pred_fn,  # y = pred_fn(x)\n",
    "            n_cfs=self.configs.n_cfs,\n",
    "            n_steps=self.configs.n_steps,\n",
    "            lr=self.configs.lr,  # learning rate for each `cf` optimization step\n",
    "            lambda_=self.configs.lambda_,  #  loss = validity_loss + lambda_params * cost\n",
    "            key=next(self.configs.keys),\n",
    "            projection_fn=self.data_module.apply_constraints,\n",
    "            regularization_fn=self.data_module.apply_regularization\n",
    "        )\n",
    "\n",
    "    def generate_cfs(\n",
    "        self,\n",
    "        X: jax.Array,  # `x` shape: (b, k), where `b` is batch size, `k` is the number of features\n",
    "        pred_fn: Callable[[jax.Array], jax.Array],\n",
    "        is_parallel: bool = False,\n",
    "    ) -> jax.Array:\n",
    "        def _generate_cf(x: jax.Array) -> jnp.ndarray:\n",
    "            return self.generate_cf(x, pred_fn)\n",
    "\n",
    "        return (\n",
    "            jax.vmap(_generate_cf)(X) if not is_parallel else jax.pmap(_generate_cf)(X)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.data import load_data\n",
    "from relax.module import PredictiveTrainingModule, PredictiveTrainingModuleConfigs, load_pred_model\n",
    "from relax.evaluate import generate_cf_explanations, benchmark_cfs\n",
    "from relax.trainer import train_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/birk/miniconda3/envs/nbdev2/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dm = load_data('adult', data_configs=dict(sample_frac=0.1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train predictive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "params, training_module = load_pred_model('adult')\n",
    "\n",
    "# predict function\n",
    "pred_fn = training_module.pred_fn\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `DiverseCF`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversecf = DiverseCF()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075f22191fd749da8a7ac5015e88eb55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| output: false\n",
    "cf_exp = generate_cf_explanations(\n",
    "    diversecf, dm, pred_fn=pred_fn, \n",
    "    pred_fn_args=dict(\n",
    "        params=params, rng_key=random.PRNGKey(0)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>validity</th>\n",
       "      <th>proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <th>DiverseCF</th>\n",
       "      <td>0.8241</td>\n",
       "      <td>0.393932</td>\n",
       "      <td>1.913267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    acc  validity  proximity\n",
       "adult DiverseCF  0.8241  0.393932   1.913267"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_cfs([cf_exp])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
