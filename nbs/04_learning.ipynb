{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "> Functions for training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipynb_path import *\n",
    "from relax.utils import show_doc\n",
    "show_doc_parser = show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from relax.import_essentials import *\n",
    "from relax.data import TabularDataModule\n",
    "from relax.module import BaseTrainingModule\n",
    "from relax.logger import TensorboardLogger\n",
    "from relax.utils import validate_configs\n",
    "from relax._ckpt_manager import CheckpointManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "class TrainingConfigs(BaseParser):\n",
    "    \"\"\"Configurator of 'train_model'.\"\"\"\n",
    "    n_epochs: int = Field(\n",
    "        None, description=\"Number of epochs.\"\n",
    "    )\n",
    "    batch_size: int = Field(\n",
    "        None, description=\"Batch size.\"\n",
    "    )\n",
    "    monitor_metrics: Optional[str] = Field(\n",
    "        None, description=\"Monitor metrics used to evaluate the training result after each epoch.\"\n",
    "    )\n",
    "    seed: int = Field(\n",
    "        42, description=\"Seed for generating random number.\"\n",
    "    )\n",
    "    log_dir: str = Field(\n",
    "        \"log\", description=\"The name for the directory that holds logged data during training.\"\n",
    "    )\n",
    "    logger_name: str = Field(\n",
    "        \"debug\", description=\"The name for the directory that holds logged data during training under log directory.\"\n",
    "    )\n",
    "    log_on_step: bool = Field(\n",
    "        False, description=\"Log the evaluate metrics at the current step.\"\n",
    "    )\n",
    "    max_n_checkpoints: int = Field(\n",
    "        3, description=\"Maximum number of checkpoints stored.\"\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def PRNGSequence(self):\n",
    "        return hk.PRNGSequence(self.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/relax/trainer.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingConfigs\n",
       "\n",
       ">      TrainingConfigs (n_epochs:int=None, batch_size:int=None,\n",
       ">                       monitor_metrics:Union[str,NoneType]=None, seed:int=42,\n",
       ">                       log_dir:str='log', logger_name:str='debug',\n",
       ">                       log_on_step:bool=False, max_n_checkpoints:int=3)\n",
       "\n",
       "Configurator of 'train_model'.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_epochs | int |  | Number of epochs. |\n",
       "| batch_size | int |  | Batch size. |\n",
       "| monitor_metrics | typing.Union[str, NoneType] |  | Monitor metrics used to evaluate the training result after each epoch. |\n",
       "| seed | int | 42 | Seed for generating random number. |\n",
       "| log_dir | str | log | The name for the directory that holds logged data during training. |\n",
       "| logger_name | str | debug | The name for the directory that holds logged data during training under log directory. |\n",
       "| log_on_step | bool | False | Log on step. |\n",
       "| max_n_checkpoints | int | 3 | Max number of checkpoints. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/birkhoffg/cfnet/tree/master/blob/master/relax/trainer.py#L15){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### TrainingConfigs\n",
       "\n",
       ">      TrainingConfigs (n_epochs:int=None, batch_size:int=None,\n",
       ">                       monitor_metrics:Union[str,NoneType]=None, seed:int=42,\n",
       ">                       log_dir:str='log', logger_name:str='debug',\n",
       ">                       log_on_step:bool=False, max_n_checkpoints:int=3)\n",
       "\n",
       "Configurator of 'train_model'.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| n_epochs | int |  | Number of epochs. |\n",
       "| batch_size | int |  | Batch size. |\n",
       "| monitor_metrics | typing.Union[str, NoneType] |  | Monitor metrics used to evaluate the training result after each epoch. |\n",
       "| seed | int | 42 | Seed for generating random number. |\n",
       "| log_dir | str | log | The name for the directory that holds logged data during training. |\n",
       "| logger_name | str | debug | The name for the directory that holds logged data during training under log directory. |\n",
       "| log_on_step | bool | False | Log on step. |\n",
       "| max_n_checkpoints | int | 3 | Max number of checkpoints. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc_parser(TrainingConfigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_model_with_states(\n",
    "    training_module: BaseTrainingModule,\n",
    "    params: hk.Params,\n",
    "    opt_state: optax.OptState,\n",
    "    data_module: TabularDataModule,\n",
    "    t_configs: Union[Dict[str, Any], TrainingConfigs],\n",
    ") -> Tuple[hk.Params, optax.OptState]:\n",
    "    t_configs = validate_configs(t_configs, TrainingConfigs)\n",
    "    keys = t_configs.PRNGSequence\n",
    "    # define logger\n",
    "    logger = TensorboardLogger(\n",
    "        log_dir=t_configs.log_dir,\n",
    "        name=t_configs.logger_name,\n",
    "        on_step=t_configs.log_on_step,\n",
    "    )\n",
    "    logger.save_hyperparams(t_configs.dict())\n",
    "    if training_module.hparams:\n",
    "        logger.save_hyperparams(training_module.hparams)\n",
    "\n",
    "    training_module.init_logger(logger)\n",
    "    # define checkpoint manageer\n",
    "    if t_configs.monitor_metrics is None:\n",
    "        monitor_metrics = None\n",
    "    else:\n",
    "        monitor_metrics = f\"{t_configs.monitor_metrics}_epoch\"\n",
    "\n",
    "    ckpt_manager = CheckpointManager(\n",
    "        log_dir=Path(training_module.logger.log_dir) / \"checkpoints\",\n",
    "        monitor_metrics=monitor_metrics,\n",
    "        max_n_checkpoints=t_configs.max_n_checkpoints,\n",
    "    )\n",
    "    # dataloaders\n",
    "    train_loader = data_module.train_dataloader(t_configs.batch_size)\n",
    "    val_loader = data_module.val_dataloader(t_configs.batch_size)\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(t_configs.n_epochs):\n",
    "        training_module.logger.on_epoch_started()\n",
    "        # training\n",
    "        with tqdm(\n",
    "            train_loader, unit=\"batch\", leave=epoch == t_configs.n_epochs - 1\n",
    "        ) as t_loader:\n",
    "            t_loader.set_description(f\"Epoch {epoch}\")\n",
    "            for batch in t_loader:\n",
    "                x, y = map(device_put, tuple(batch))\n",
    "                params, opt_state = training_module.training_step(\n",
    "                    params, opt_state, next(keys), (x, y)\n",
    "                )\n",
    "                # logs = training_module.training_step_logs(\n",
    "                #     params, next(keys), (x, y))\n",
    "                logs = training_module.logger.get_last_logs()\n",
    "                t_loader.set_postfix(**logs)\n",
    "                # logger.log(logs)\n",
    "\n",
    "        # validation\n",
    "        for batch in val_loader:\n",
    "            x, y = map(device_put, tuple(batch))\n",
    "            logs = training_module.validation_step(params, next(keys), (x, y))\n",
    "            # logger.log(logs)\n",
    "        epoch_logs = training_module.logger.on_epoch_finished()\n",
    "        ckpt_manager.update_checkpoints(params, opt_state, epoch_logs, epoch)\n",
    "\n",
    "    training_module.logger.close()\n",
    "    return params, opt_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def train_model(\n",
    "    training_module: BaseTrainingModule, # Training module\n",
    "    data_module: TabularDataModule, # Data module\n",
    "    t_configs: Union[Dict[str, Any], TrainingConfigs], # Training configurator\n",
    ") -> Tuple[hk.Params, optax.OptState]:\n",
    "    \"\"\"Train machine learning classifier\"\"\"\n",
    "    t_configs = validate_configs(t_configs, TrainingConfigs)\n",
    "    keys = t_configs.PRNGSequence \n",
    "    params, opt_state = training_module.init_net_opt(data_module, next(keys))\n",
    "    return train_model_with_states(\n",
    "        training_module=training_module,\n",
    "        params=params,\n",
    "        opt_state=opt_state,\n",
    "        data_module=data_module,\n",
    "        t_configs=t_configs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.data import TabularDataModule\n",
    "from relax.module import PredictiveTrainingModule\n",
    "\n",
    "data_configs = {\n",
    "    \"data_dir\": \"assets/data/s_adult.csv\",\n",
    "    \"data_name\": \"adult\",\n",
    "    \"batch_size\": 256,\n",
    "    'sample_frac': 0.1,\n",
    "    \"continous_cols\": [\n",
    "        \"age\",\n",
    "        \"hours_per_week\"\n",
    "    ],\n",
    "    \"discret_cols\": [\n",
    "        \"workclass\",\n",
    "        \"education\",\n",
    "        \"marital_status\",\n",
    "        \"occupation\",\n",
    "        \"race\",\n",
    "        \"gender\"\n",
    "    ],\n",
    "}\n",
    "# dm = \n",
    "m_configs = {\n",
    "    \"sizes\": [50, 10, 50],\n",
    "    \"dropout_rate\": 0.3,\n",
    "    'lr': 0.003,\n",
    "}\n",
    "t_configs = {\n",
    "    'n_epochs': 10,\n",
    "    'monitor_metrics': 'val/val_loss',\n",
    "    'seed': 42,\n",
    "    \"batch_size\": 256\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from relax.module import PredictiveTrainingModule\n",
    "\n",
    "params, opt_state = train_model(\n",
    "    PredictiveTrainingModule(m_configs), \n",
    "    TabularDataModule(data_configs), \n",
    "    t_configs\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cfnet",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
